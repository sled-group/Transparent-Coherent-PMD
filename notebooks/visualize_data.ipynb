{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609598b0-4653-4b42-85ba-2a38a01e4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"/nfs/turbo/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl\")\n",
    "os.environ['TRAVEl_config_path'] = \"/nfs/turbo/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/config_regen_ego4d.yml\"\n",
    "from travel import init_travel\n",
    "init_travel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460eb69c-dc5c-4e68-b980-6aabe4c6921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/config_regen_ego4d.yml /nfs/turbo/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl_generated_data_0808\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from travel.constants import CONFIG_PATH, DATA_CACHE_DIR\n",
    "from travel.data.ego4d import FRAME_KEEP_FREQUENCY\n",
    "print(CONFIG_PATH, DATA_CACHE_DIR)\n",
    "print(FRAME_KEEP_FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388735e-8531-4f6d-a3fb-9426fd4871df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7e6b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CaptainCook4D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94c217d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from travel.data.captaincook4d import CaptainCook4DDataset\n",
    "\n",
    "PARTITION = \"val\"\n",
    "\n",
    "# Load mistake detection dataset\n",
    "dataset = CaptainCook4DDataset(data_split=PARTITION,\n",
    "                               debug_n_examples_per_class=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46007c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find CaptainCook4D example 1_37_0.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# RETRIEVE_ID = \"10_46_1\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# RETRIEVE_TIMES = [\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#                 0.0,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#                 80.0\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#             ]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     retrieve_example \u001b[38;5;241m=\u001b[39m [example \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m example\u001b[38;5;241m.\u001b[39mexample_id \u001b[38;5;241m==\u001b[39m RETRIEVE_ID][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find CaptainCook4D example \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRETRIEVE_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RETRIEVE_ID = \"1_37_0\"\n",
    "RETRIEVE_TIMES = [\n",
    "                14.0,\n",
    "                16.0,\n",
    "                18.0,\n",
    "                22.0,\n",
    "                24.0,\n",
    "                26.0,\n",
    "                28.0,\n",
    "                30.0,\n",
    "                32.0,\n",
    "                34.0\n",
    "            ]\n",
    "\n",
    "# RETRIEVE_ID = \"10_46_1\"\n",
    "# RETRIEVE_TIMES = [\n",
    "#                 0.0,\n",
    "#                 2.0,\n",
    "#                 4.0,\n",
    "#                 6.0,\n",
    "#                 10.0,\n",
    "#                 14.0,\n",
    "#                 16.0,\n",
    "#                 18.0,\n",
    "#                 20.0,\n",
    "#                 22.0,\n",
    "#                 24.0,\n",
    "#                 24.516\n",
    "#             ]\n",
    "\n",
    "# RETRIEVE_ID = \"1_37_2\"\n",
    "# RETRIEVE_TIMES = [\n",
    "#                 0.0,\n",
    "#                 6.0,\n",
    "#                 80.0\n",
    "#             ]\n",
    "\n",
    "try:\n",
    "    retrieve_example = [example for example in dataset if example.example_id == RETRIEVE_ID][0]\n",
    "except:\n",
    "    print(f\"Could not find CaptainCook4D example {RETRIEVE_ID}.\")\n",
    "    raise\n",
    "\n",
    "for time in RETRIEVE_TIMES:\n",
    "    found_frame = False\n",
    "    for frame, frame_time in zip(retrieve_example.frames, retrieve_example.frame_times):\n",
    "        if round(frame_time, 1) == round(time, 1):\n",
    "            found_frame = True\n",
    "            plt.imshow(frame)\n",
    "            plt.title(f\"Example {retrieve_example.example_id} - Time {round(time,1)}\")\n",
    "            plt.show()\n",
    "    if not found_frame:\n",
    "        print(f\"Could not find frame at time {time} in example {retrieve_example.example_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38875e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "from travel.constants import MODEL_CACHE_DIR\n",
    "import os\n",
    "os.environ['HF_HOME'] = MODEL_CACHE_DIR\n",
    "\n",
    "from travel.model.vqg import load_vqg_outputs\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq, Owlv2Processor, Owlv2ForObjectDetection\n",
    "\n",
    "vqg_outputs = load_vqg_outputs(\"/home/sstorks/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results/vqg/VQG_Llama-2-7b-hf_icl5_20240227131939\")\n",
    "\n",
    "# Load OWL object detector for filtering frames, and filter frames\n",
    "detector_processor = Owlv2Processor.from_pretrained(\"google/owlv2-base-patch16\")\n",
    "detector = Owlv2ForObjectDetection.from_pretrained(\"google/owlv2-base-patch16\", load_in_8bit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de57f7af-c3a5-428a-af2a-421b70c16464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detecting objects with threshold 0.2: 100%|██████████| 113/113 [04:00<00:00,  2.13s/it]\n",
      "filtering frames: 100%|██████████| 40/40 [00:00<00:00, 18676.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 576 video frames (904 -> 328).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from travel.model.grounding import filter_frames_by_target_objects\n",
    "\n",
    "dataset = filter_frames_by_target_objects(dataset, detector, detector_processor, vqg_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb6f5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ego4D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965ef2b6-0a0d-4dd7-9b14-e6cc5b772948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Found 0 processed videos, still need to process 21634 clips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 4/21634 [00:11<18:27:02,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip 8532e114-f8e4-42b5-987b-fcf0ebb32bf5/4!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 8/21634 [00:24<17:28:36,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 9/21634 [00:27<17:06:10,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip 8532e114-f8e4-42b5-987b-fcf0ebb32bf5/9!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 13/21634 [00:50<30:06:56,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 14/21634 [00:58<35:06:07,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/3!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 15/21634 [01:07<40:58:06,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/4!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 16/21634 [01:17<47:57:24,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 17/21634 [01:26<48:12:16,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 18/21634 [01:33<46:54:17,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/7!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 19/21634 [01:43<51:48:07,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/8!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 20/21634 [01:50<47:33:01,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/9!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 21/21634 [01:53<39:49:59,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/10!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 23/21634 [02:11<46:51:28,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 24/21634 [02:14<36:34:42,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/13!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 25/21634 [02:17<32:10:58,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/14!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 26/21634 [02:22<31:42:29,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/15!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 27/21634 [02:25<27:54:25,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 29/21634 [02:38<34:42:00,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/18!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 30/21634 [02:47<39:03:04,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 31/21634 [02:53<39:23:56,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 32/21634 [02:57<34:58:03,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/21!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 33/21634 [03:01<31:29:45,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/22!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 34/21634 [03:07<32:58:45,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None) Warning: Could not generate a hard negative for clip ce2cf2f6-24aa-4195-93a6-f82b283815e6/23!\n",
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(None) generating ego4d data:   0%|          | 34/21634 [03:13<34:05:54,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO MISALIGNSRL SAMPLE ANNOTATED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from travel.data.ego4d import Ego4DMistakeDetectionDataset\n",
    "\n",
    "dataset = Ego4DMistakeDetectionDataset(data_split=\"val\",\n",
    "                                               mismatch_augmentation=True,\n",
    "                                               multi_frame=False,\n",
    "                                      debug_n_examples_per_class=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217bb765-3027-409f-b059-e06acff54ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((False, None), 25),\n",
      " ((True, 'Action Incomplete'), 10),\n",
      " ((True, 'MisalignSRL_ARG1'), 3),\n",
      " ((True, 'MisalignSRL_V_ARG1'), 3)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "mistake_dist = Counter()\n",
    "for example in dataset:\n",
    "    mistake_dist[(example.mistake, example.mistake_type)] += 1\n",
    "\n",
    "pprint(mistake_dist.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e704f702-fb67-4e93-86ce-b90b14bf3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "examples_to_visualize = random.sample(list(range(len(dataset))), 30)\n",
    "# examples_to_visualize = list(range(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68736c68-b29c-4ca1-bf58-a1e18df678a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from travel.data.utils.image import variance_of_laplacian\n",
    "\n",
    "for example_idx in examples_to_visualize:\n",
    "    \n",
    "    example = dataset[example_idx]\n",
    "    \n",
    "    print(\"\")\n",
    "    print(example.procedure_description)\n",
    "    print(f\"{'Success' if not example.mistake else 'Mistake'} ({example.mistake_type})\")\n",
    "    duration = example.frame_times[-1] - example.frame_times[0]\n",
    "    print(example.frame_times)\n",
    "    print(f\"({duration} sec.)\")\n",
    "    print(f\"Example ID: {example.example_id}\")\n",
    "    print(\"Verb noun pair:\", example.verb_noun_pair)\n",
    "    \n",
    "    frame_lightnesses = [np.mean(np.asarray(frame)) / 255.0 for frame in example.frames]\n",
    "    print(\"Frame lightness (mean):\", np.mean(frame_lightnesses))\n",
    "    print(\"Frame blurriness:\", [variance_of_laplacian(frame) for frame in example.frames])\n",
    "    \n",
    "    fig, axarr = plt.subplots(1, len(example.frames), figsize=(22, 4))\n",
    "\n",
    "    # Ensure axarr is always iterable\n",
    "    if len(example.frames) == 1:\n",
    "        axarr = [axarr]\n",
    "\n",
    "    for frame, ax in zip(example.frames, axarr):\n",
    "        if frame is not None:\n",
    "            ax.imshow(frame)\n",
    "            ax.axis('off')  # Hide the axes for better visualization\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667d0e6-a944-4986-9edd-732e92506d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816ab87-6197-479f-aafc-75dccf66d61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "672b6b45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# VQG Training Data from Ego4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fbe337",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results/vqg_learning/VQG_data_debug_Llama-2-7b-hf_icl5_20240429110645/frameVQA_examples.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m RESULTS_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results/vqg_learning/VQG_data_debug_Llama-2-7b-hf_icl5_20240429110645\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RESULTS_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframeVQA_examples.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m120\u001b[39m]:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# pprint(example)\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results/vqg_learning/VQG_data_debug_Llama-2-7b-hf_icl5_20240429110645/frameVQA_examples.pkl'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "RESULTS_DIR = \"coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results/vqg_learning/VQG_data_debug_Llama-2-7b-hf_icl5_20240429110645\"\n",
    "data_path = os.path.join(RESULTS_DIR, \"frameVQA_examples.pkl\")\n",
    "data = pickle.load(open(data_path, \"rb\"))\n",
    "\n",
    "print(f\"{len(data)} examples generated\")\n",
    "for example in data[100:120]:\n",
    "    # pprint(example)\n",
    "\n",
    "    for question_set in example.candidate_question_sets:\n",
    "        fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "        # Display the image\n",
    "        ax.imshow(example.frame)\n",
    "\n",
    "        # Adding text on the image at different positions\n",
    "        text_offset = 30  # Pixel offset for text below the image\n",
    "        ax.text(0, example.frame.height + 35, question_set.procedure_description, fontsize=9, style='italic')\n",
    "        ax.text(0, example.frame.height + 70, f\"{question_set.questions[0]} ({question_set.answers[0].name})\", fontsize=9)\n",
    "        ax.text(0, example.frame.height + 105, f\"{question_set.questions[1]} ({question_set.answers[1].name})\", fontsize=9)\n",
    "\n",
    "        # Set the limits of the axes and hide them\n",
    "        ax.set_xlim([0, example.frame.width])\n",
    "        ax.set_ylim([example.frame.height + text_offset + 50, -10])  # Expanded to fit the text below the image\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Display the figure\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd6dad-d1ef-44c1-80c8-e3542322e83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel",
   "language": "python",
   "name": "travel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
