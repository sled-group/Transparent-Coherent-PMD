{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609598b0-4653-4b42-85ba-2a38a01e4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"/nfs/turbo/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl\")\n",
    "from travel import init_travel\n",
    "init_travel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dfe59f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f0084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_probs': [[0.228156, 0.771843],\n",
      "                  [0.507812, 0.492188],\n",
      "                  [0.272025, 0.727975],\n",
      "                  [0.721743, 0.278257],\n",
      "                  [0.573678, 0.426322],\n",
      "                  [0.304042, 0.695958],\n",
      "                  [0.052619, 0.947381],\n",
      "                  [0.909907, 0.090093],\n",
      "                  [0.841826, 0.158174],\n",
      "                  [0.800692, 0.199308]],\n",
      " 'answers': [1, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
      " 'candidate_questions': [[\"Is the paper in the person's hand?\",\n",
      "                          'Is the paper wet?',\n",
      "                          \"Is the paper in the person's hands?\"],\n",
      "                         [\"Is the paper in the person's hand folded?\",\n",
      "                          \"Is the paper in the person's hand wet?\",\n",
      "                          \"Is the liquid in the person's hand?\"],\n",
      "                         [\"Is the paper in the person's hand unfolded?\",\n",
      "                          \"Is the paper in the person's hand open?\",\n",
      "                          \"Is the paper in the person's hand flat?\",\n",
      "                          \"Is the paper in the person's hand white?\"],\n",
      "                         [\"Is the paper in the person's hand white?\",\n",
      "                          \"Is the paper in the person's hand wet?\",\n",
      "                          \"Is the paper in the person's hand flat?\",\n",
      "                          \"Is the paper in the person's hand empty?\"],\n",
      "                         [\"Is the paper in the person's hand wet?\",\n",
      "                          \"Is the paper in the person's hand crumpled?\",\n",
      "                          \"Is the paper in the person's hand wrinkled?\",\n",
      "                          \"Is the paper in the person's hand curled up?\"],\n",
      "                         [\"Is the paper in the person's hand wet?\",\n",
      "                          \"Is the paper in the person's hand wrinkled?\",\n",
      "                          \"Is the paper in the person's hand folded in half?\",\n",
      "                          \"Is the paper in the person's hand smooth?\"],\n",
      "                         [\"Is the paper in the person's hand wet?\",\n",
      "                          \"Is the paper in the person's hand white?\",\n",
      "                          \"Is the liquid in the person's hand?\",\n",
      "                          'Is the person holding the paper in their right '\n",
      "                          'hand?'],\n",
      "                         [\"Is the liquid in the person's hand clear?\",\n",
      "                          \"Is the liquid in the person's hand in a container?\",\n",
      "                          \"Is the liquid in the person's hand a beverage?\",\n",
      "                          \"Is the liquid in the person's hand a small amount?\"],\n",
      "                         [\"Is the liquid in the person's hand a beverage?\",\n",
      "                          \"Is the liquid in the person's hand a cup?\",\n",
      "                          \"Is the liquid in the person's hand a bottle?\",\n",
      "                          \"Is the liquid in the person's hand in a bottle?\"],\n",
      "                         [\"Is the liquid in the person's hand in a cup?\",\n",
      "                          \"Is the liquid in the person's hand a cup?\",\n",
      "                          \"Is the liquid in the person's hand a beverage?\",\n",
      "                          \"Is the liquid in the person's hand in a glass?\"]],\n",
      " 'candidate_questions_scores': [[-2.671022415161133,\n",
      "                                 -5.056441783905029,\n",
      "                                 -2.8008642196655273],\n",
      "                                [-1.748389720916748,\n",
      "                                 -1.9243320226669312,\n",
      "                                 -2.4637410640716553],\n",
      "                                [-1.573311686515808,\n",
      "                                 -1.5037479400634766,\n",
      "                                 -1.722647786140442,\n",
      "                                 -1.5139137506484985],\n",
      "                                [-1.7830920219421387,\n",
      "                                 -1.9611274003982544,\n",
      "                                 -1.765828251838684,\n",
      "                                 -1.8446731567382812],\n",
      "                                [-2.279223680496216,\n",
      "                                 -1.6689256429672241,\n",
      "                                 -1.8803930282592773,\n",
      "                                 -1.719415307044983],\n",
      "                                [-3.63576078414917,\n",
      "                                 -3.1232712268829346,\n",
      "                                 -3.4543375968933105,\n",
      "                                 -3.588766098022461],\n",
      "                                [-5.905271053314209,\n",
      "                                 -5.93673038482666,\n",
      "                                 -5.611351013183594,\n",
      "                                 -6.1317596435546875],\n",
      "                                [-8.002975463867188,\n",
      "                                 -7.5762529373168945,\n",
      "                                 -7.913816928863525,\n",
      "                                 -7.6964497566223145],\n",
      "                                [-9.654524803161621,\n",
      "                                 -9.80082893371582,\n",
      "                                 -9.062565803527832,\n",
      "                                 -9.007826805114746],\n",
      "                                [-9.898186683654785,\n",
      "                                 -9.996386528015137,\n",
      "                                 -9.834456443786621,\n",
      "                                 -9.894169807434082]],\n",
      " 'candidate_questions_sources': [['vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm'],\n",
      "                                 ['vlm', 'vlm', 'vlm', 'vlm']],\n",
      " 'example_id': '90093217-6a61-48ce-b737-e581499cf491/144/pos',\n",
      " 'final_success_prob': 0.594551,\n",
      " 'final_turn': 4,\n",
      " 'frame_dir': '/nfs/turbo/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl_generated_data_0808/ego4d_val_seed222_mismatch_debug250/90093217-6a61-48ce-b737-e581499cf491/144/pos',\n",
      " 'informativeness_marginal': [0.264648, 0.208984, 0.0, 0.006836, 0.000488],\n",
      " 'informativeness_marginal_x_relevance_marginal': [0.02739,\n",
      "                                                   0.009079,\n",
      "                                                   0.0,\n",
      "                                                   0.000794,\n",
      "                                                   0.000184],\n",
      " 'mistake': False,\n",
      " 'mistake_type': None,\n",
      " 'procedure': 'Put liquid in the paper',\n",
      " 'questions': [\"Is the paper in the person's hand?\",\n",
      "               \"Is the paper in the person's hand folded?\",\n",
      "               \"Is the paper in the person's hand open?\",\n",
      "               \"Is the paper in the person's hand flat?\",\n",
      "               \"Is the paper in the person's hand crumpled?\",\n",
      "               \"Is the paper in the person's hand wrinkled?\",\n",
      "               \"Is the liquid in the person's hand?\",\n",
      "               \"Is the liquid in the person's hand in a container?\",\n",
      "               \"Is the liquid in the person's hand in a bottle?\",\n",
      "               \"Is the liquid in the person's hand a beverage?\"],\n",
      " 'relevance_marginal': [0.103516, 0.043457, 0.061523, 0.116211, 0.376709],\n",
      " 'scores': [-2.671022415161133,\n",
      "            -1.748389720916748,\n",
      "            -1.5037479400634766,\n",
      "            -1.765828251838684,\n",
      "            -1.6689256429672241,\n",
      "            -3.1232712268829346,\n",
      "            -5.611351013183594,\n",
      "            -7.5762529373168945,\n",
      "            -9.007826805114746,\n",
      "            -9.834456443786621],\n",
      " 'success_probs': [0.560253,\n",
      "                   0.537041,\n",
      "                   0.656658,\n",
      "                   0.635222,\n",
      "                   0.594551,\n",
      "                   0.607663,\n",
      "                   0.712232,\n",
      "                   0.713831,\n",
      "                   0.684264,\n",
      "                   0.70253],\n",
      " 'success_probs_negated': []}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "RESULTS_PATH_LIKELIHOOD = \"/home/sstorks/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results_222/vqa_mistake_detection/ego4d_single_debug250/llava-1.5-7b-hf/IterativeVQA_q10_ego4d_single_debug250_llava-1.5-7b-hf_beam8-4_likelihood_20240812143853\"\n",
    "preds_l = json.load(open(os.path.join(RESULTS_PATH_LIKELIHOOD, \"outputs_val.json\"), \"r\"))\n",
    "metrics_l = json.load(open(os.path.join(RESULTS_PATH_LIKELIHOOD, \"metrics_coherence_nli_val.json\"), \"r\"))\n",
    "combined_l = [v | {\"example_id\": k, \n",
    "                   \"relevance_marginal\": metrics_l['metrics_by_turn']['relevance_marginal_by_turn'][i], \n",
    "                   \"informativeness_marginal\": metrics_l['metrics_by_turn']['informativeness_marginal_by_turn'][i],\n",
    "                   \"informativeness_marginal_x_relevance_marginal\": metrics_l['metrics_by_turn']['informativeness_marginal_x_relevance_marginal_by_turn'][i],} for i, (k, v) in enumerate(preds_l.items())]\n",
    "\n",
    "combined_c = []\n",
    "# RESULTS_PATH_COHERENCE = \"/home/sstorks/coe-chaijy/sstorks/simulation_informed_pcr4nlu/TRAVEl/saved_results_222/vqa_mistake_detection/ego4d_single_debug250/llava-1.5-7b-hf/IterativeVQA_q10_ego4d_single_debug250_llava-1.5-7b-hf_coherence_icl20_20240810135720\"\n",
    "# preds_c = json.load(open(os.path.join(RESULTS_PATH_COHERENCE, \"outputs_val.json\"), \"r\"))\n",
    "# metrics_c = json.load(open(os.path.join(RESULTS_PATH_COHERENCE, \"metrics_coherence_nli_val.json\"), \"r\"))\n",
    "# combined_c = [v | {\"example_id\": k, \n",
    "#                    \"relevance_marginal\": metrics_l['metrics_by_turn']['relevance_marginal_by_turn'][i], \n",
    "#                    \"informativeness_marginal\": metrics_l['metrics_by_turn']['informativeness_marginal_by_turn'][i],\n",
    "#                    \"informativeness_marginal_x_relevance_marginal\": metrics_l['metrics_by_turn']['informativeness_marginal_x_relevance_marginal_by_turn'][i],} for i, (k, v) in enumerate(preds_c.items())]\n",
    "\n",
    "all_data = combined_l + combined_c\n",
    "\n",
    "pprint(all_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec2d81-c7c5-483d-bbb1-e9535d28a6be",
   "metadata": {},
   "source": [
    "# Select turns and candidates to score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbf567-d550-49af-835d-06a95cc1dac2",
   "metadata": {},
   "source": [
    "Relevance study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bcaca06-bf06-45d4-8251-724de8603281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "from travel import set_random_seed\n",
    "from travel.constants import RANDOM_SEED, RESULTS_DIR\n",
    "\n",
    "N_SAMPLES = 50\n",
    "SAMPLES_PER_ANNOTATOR = 10\n",
    "\n",
    "timestamp = datetime.datetime.now()\n",
    "output_dir = os.path.join(RESULTS_DIR, \"annotation_files\", f\"relevance_{timestamp.strftime('%Y%m%d%H%M%S')}\")\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "random_seed = 555\n",
    "set_random_seed(random_seed) # Set seed to 555 for relevance samples\n",
    "\n",
    "example_idxs = random.sample(list(range(len(all_data))), N_SAMPLES)\n",
    "\n",
    "data_dicts = []\n",
    "for example_idx in example_idxs:\n",
    "    output = all_data[example_idx]\n",
    "    example_id = output['example_id']\n",
    "\n",
    "    n_turns = output['final_turn'] + 1\n",
    "    selected_turn = random.choice(list(range(n_turns)))\n",
    "\n",
    "    selected_question = output['questions'][selected_turn]\n",
    "    selected_answer = output['answers'][selected_turn]\n",
    "    selected_answer = \"Yes\" if selected_answer == 1 else \"No\"\n",
    "\n",
    "    previous_questions = output['questions'][:selected_turn]\n",
    "    previous_answers = [\"Yes\" if a == 1 else \"No\" for a in output['answers'][:selected_turn]]\n",
    "\n",
    "    actual_relevance_marginal = output['relevance_marginal'][selected_turn]\n",
    "    actual_informativeness_marginal = output['informativeness_marginal'][selected_turn]\n",
    "    actual_informativeness_marginal_x_relevance_marginal = output['informativeness_marginal_x_relevance_marginal'][selected_turn]\n",
    "                                  \n",
    "    data_dicts.append(\n",
    "        {\n",
    "            \"example_id\": example_id,\n",
    "            \"procedure\": output['procedure'],\n",
    "            \"question\": selected_question,\n",
    "            \"previous_questions_answers\": [(q, a) for q, a in zip(previous_questions, previous_answers)],\n",
    "            \"nli_metric_scores\": {\n",
    "                \"relevance_marginal\": actual_relevance_marginal,\n",
    "                \"informativeness_marginal\": actual_informativeness_marginal,\n",
    "                \"informativeness_marginal_x_relevance_marginal\": actual_informativeness_marginal_x_relevance_marginal,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "json.dump(data_dicts, open(os.path.join(output_dir, f\"relevance_sample{random_seed}.json\"), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea9c6066-4fdc-4ab5-abd7-8b9e97d73f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide sampled data into a txt file for each annotator\n",
    "for annotator_idx in range(N_SAMPLES // SAMPLES_PER_ANNOTATOR):\n",
    "    lines = []\n",
    "\n",
    "    samples = data_dicts[annotator_idx * SAMPLES_PER_ANNOTATOR:(annotator_idx + 1) * SAMPLES_PER_ANNOTATOR]\n",
    "    assert len(samples) == SAMPLES_PER_ANNOTATOR\n",
    "    \n",
    "    lines.append(\"Imagine you just had eye surgery, and are unable to see. You're performing a task you're familiar with, but need help to determine whether you successfully completed it.\")\n",
    "    lines.append(\"You video call a friend (who is unfamiliar with the task) and show them what you're working on. You then ask them some yes/no questions to figure out whether you successfully completed the task.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"For each annotation task, you will be given the following information:\")\n",
    "    lines.append(\" - A sentence describing the procedure you're trying to perform.\")\n",
    "    lines.append(\" - An optional list of previous questions you already asked, and their answers.\")\n",
    "    lines.append(\" - A potential question you could ask your friend next.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"You must rate how relevant the potential next question is. By relevant, we mean: given the previous questions and answers, how helpful could an answer to this question be in determining whether the procedure has been completed?\")\n",
    "    lines.append(\"You can also choose to mark 'Instructions Unclear', which means that the instructional text itself is not clear, so you're not sure how to determine whether it's successful. This should only be used in rare cases.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Some tips:\")\n",
    "    lines.append(\" - Only judge the relevance of the potential next question, not the previous questions (which may or may not be relevant).\")\n",
    "    lines.append(\" - A question may seem relevant to the task at hand, but you should consider it irrelevant if it doesn't provide essential information to judge the success of the task.\")\n",
    "    lines.append(\" - If a seemingly relevant question is redundant with previous questions, you may consider it less relevant.\")\n",
    "    lines.append(\" - Assume that the answer to the question won't contradict the information you have from previous questions and answers. If previous questions and answers already contradict each other, consider whether this question could sway you one way or another.\")\n",
    "    lines.append(' - The instructional text and questions may refer to \"someone\" or a \"person\"; always assume this is referring to yourself (the person performing the task).')\n",
    "    lines.append(' - The questions may refer to a \"photo\" or \"image\"; always assume this is referring to the video feed your friend would see through the video call.')\n",
    "    lines.append(\"\\n\")\n",
    "                 \n",
    "    # How relevant is this question, i.e., how useful would an answer to this question be in determining whether the procedure has been completed?\n",
    "    for sample_idx, sample in enumerate(samples):\n",
    "        lines.append(f\"Annotation {sample_idx + 1}\")\n",
    "        lines.append(\"===============================\")\n",
    "        lines.append(f\"Instruction: {sample['procedure']}\")\n",
    "        \n",
    "        lines.append(\"Previous questions and answers:\")\n",
    "        if len(sample['previous_questions_answers']) == 0:\n",
    "            lines.append(\"None\")\n",
    "        else:\n",
    "            for q_idx, (q, a) in enumerate(sample['previous_questions_answers']):\n",
    "                 lines.append(f\"Q{q_idx+1}. {q}     (Answer: {a})\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"Potential next question: {sample['question']}\")\n",
    "        lines.append(\"Your rating (place an 'x' next to your choice):\")\n",
    "        lines.append(\"1 (very irrelevant): \")\n",
    "        lines.append(\"2 (slightly irrelevant): \")\n",
    "        lines.append(\"3 (neutral): \")\n",
    "        lines.append(\"4 (slightly relevant): \")\n",
    "        lines.append(\"5 (very relevant): \")\n",
    "        lines.append(\"Instructions Unclear: \")\n",
    "        lines.append(\"\\n\")\n",
    "                 \n",
    "    with open(os.path.join(output_dir, f\"relevance_sample{random_seed}_annotator{annotator_idx+1}.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75182c9c-1166-4d71-b13f-28d129b0b1c1",
   "metadata": {},
   "source": [
    "Informativeness study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db5a3ae4-538d-4f24-9a37-345f0b4df68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "from travel import set_random_seed\n",
    "from travel.constants import RANDOM_SEED, RESULTS_DIR\n",
    "\n",
    "N_SAMPLES = 50\n",
    "SAMPLES_PER_ANNOTATOR = 10\n",
    "\n",
    "timestamp = datetime.datetime.now()\n",
    "output_dir = os.path.join(RESULTS_DIR, \"annotation\", f\"informativeness_{timestamp.strftime('%Y%m%d%H%M%S')}\")\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "random_seed = 888\n",
    "set_random_seed(random_seed) # Set seed to 888 for informativeness samples\n",
    "\n",
    "example_idxs = random.sample(list(range(len(all_data))), N_SAMPLES)\n",
    "\n",
    "data_dicts = []\n",
    "for example_idx in example_idxs:\n",
    "    output = all_data[example_idx]\n",
    "    example_id = output['example_id']\n",
    "\n",
    "    n_turns = output['final_turn'] + 1\n",
    "    selected_turn = random.choice(list(range(n_turns)))\n",
    "\n",
    "    selected_question = output['questions'][selected_turn]\n",
    "    selected_answer = output['answers'][selected_turn]\n",
    "    selected_answer = \"Yes\" if selected_answer == 1 else \"No\"\n",
    "\n",
    "    previous_questions = output['questions'][:selected_turn]\n",
    "    previous_answers = [\"Yes\" if a == 1 else \"No\" for a in output['answers'][:selected_turn]]\n",
    "\n",
    "    actual_relevance_marginal = output['relevance_marginal'][selected_turn]\n",
    "    actual_informativeness_marginal = output['informativeness_marginal'][selected_turn]\n",
    "    actual_informativeness_marginal_x_relevance_marginal = output['informativeness_marginal_x_relevance_marginal'][selected_turn]\n",
    "                                  \n",
    "    data_dicts.append(\n",
    "        {\n",
    "            \"example_id\": example_id,\n",
    "            \"procedure\": output['procedure'],\n",
    "            \"question\": selected_question,\n",
    "            \"answer\": selected_answer,\n",
    "            \"previous_questions_answers\": [(q, a) for q, a in zip(previous_questions, previous_answers)],\n",
    "            \"nli_metric_scores\": {\n",
    "                \"relevance_marginal\": actual_relevance_marginal,\n",
    "                \"informativeness_marginal\": actual_informativeness_marginal,\n",
    "                \"informativeness_marginal_x_relevance_marginal\": actual_informativeness_marginal_x_relevance_marginal,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "json.dump(data_dicts, open(os.path.join(output_dir, f\"informativeness_sample{random_seed}.json\"), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b09b0859-6f8e-43be-92b8-95f8e62cca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide sampled data into a txt file for each annotator\n",
    "for annotator_idx in range(N_SAMPLES // SAMPLES_PER_ANNOTATOR):\n",
    "    lines = []\n",
    "\n",
    "    samples = data_dicts[annotator_idx * SAMPLES_PER_ANNOTATOR:(annotator_idx + 1) * SAMPLES_PER_ANNOTATOR]\n",
    "    assert len(samples) == SAMPLES_PER_ANNOTATOR\n",
    "    \n",
    "    lines.append(\"Imagine you just had eye surgery, and are unable to see. You're performing a task you're familiar with, but need help to determine whether you successfully completed it.\")\n",
    "    lines.append(\"You video call a friend (who is unfamiliar with the task) and show them what you're working on. You then ask them some yes/no questions to figure out whether you successfully completed the task.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"For each annotation task, you will be given the following information:\")\n",
    "    lines.append(\" - A sentence describing the procedure you're trying to perform.\")\n",
    "    lines.append(\" - An optional list of previous questions you already asked, and their answers.\")\n",
    "    lines.append(\" - The last question you just asked your friend, and its answer.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"You must rate how informative the last question and its answer are. By informative, we mean: compared to what you knew from the previous questions and answers, how much more sure would the last question and answer be about whether you succeeded?\")\n",
    "    lines.append(\"You can also choose to mark 'Instructions Unclear', which means that the instructional text itself is not clear, so you're not sure how to determine whether it's successful. This should only be used in rare cases.\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"Some tips:\")\n",
    "    lines.append(\" - Only judge the informativeness of the last question and answer, not the previous questions and answers (which may or may not be informative).\")\n",
    "    lines.append(\" - A question may seem relevant to the task at hand, but you should consider it uninformative if it doesn't provide essential information to judge the success of the task.\")\n",
    "    lines.append(\" - If a seemingly informative question is redundant with previous questions, you may consider it less informative.\")\n",
    "    lines.append(\" - If the last answer contradicts critical information you had from previous questions and answers, you may consider it more informative.\")\n",
    "    lines.append(' - The instructional text and questions may refer to \"someone\" or a \"person\"; always assume this is referring to yourself (the person performing the task).')\n",
    "    lines.append(' - The questions may refer to a \"photo\" or \"image\"; always assume this is referring to the video feed your friend would see through the video call.')\n",
    "    lines.append(\"\\n\")\n",
    "                 \n",
    "    # How relevant is this question, i.e., how useful would an answer to this question be in determining whether the procedure has been completed?\n",
    "    for sample_idx, sample in enumerate(samples):\n",
    "        lines.append(f\"Annotation {sample_idx + 1}\")\n",
    "        lines.append(\"===============================\")\n",
    "        lines.append(f\"Instruction: {sample['procedure']}\")\n",
    "        \n",
    "        lines.append(\"Previous questions and answers:\")\n",
    "        if len(sample['previous_questions_answers']) == 0:\n",
    "            lines.append(\"None\")\n",
    "        else:\n",
    "            for q_idx, (q, a) in enumerate(sample['previous_questions_answers']):\n",
    "                 lines.append(f\"Q{q_idx+1}. {q}     (Answer: {a})\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"Last question: {sample['question']}\")\n",
    "        lines.append(f\"Last answer: {sample['answer']}\")\n",
    "        lines.append(\"Your rating (place an 'x' next to your choice):\")\n",
    "        lines.append(\"1 (very informative): \")\n",
    "        lines.append(\"2 (slightly informative): \")\n",
    "        lines.append(\"3 (neutral): \")\n",
    "        lines.append(\"4 (slightly informative): \")\n",
    "        lines.append(\"5 (very informative): \")\n",
    "        lines.append(\"Instructions Unclear: \")\n",
    "        lines.append(\"\\n\")\n",
    "                 \n",
    "    with open(os.path.join(output_dir, f\"informativeness_sample{random_seed}_annotator{annotator_idx+1}.txt\"), \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743f783-2979-442d-9d33-fcf347f4914d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel",
   "language": "python",
   "name": "travel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
