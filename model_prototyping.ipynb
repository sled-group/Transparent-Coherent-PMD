{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CACHE_DIR = \"/scratch/chaijy_root/chaijy0/sstorks/.cache/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load WTaG toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from pipeline.py in WTaG code\n",
    "\n",
    "from travel.wtag.util import *\n",
    "\n",
    "def genAndCall(prompt_recipe, chat_history, timei, fill_user_asr=None, fill_inst_asr=None, \\\n",
    "\t\t\t\t\t\t\t\t\tvb_generated_text=None, predicted_objects=None):\n",
    "\tprompt_i, prompt_obi = get_prompt(prompt_recipe, chat_history, timei, fill_user_asr=fill_user_asr, \\\n",
    "\t\t\t\t\t\t\tfill_inst_asr=fill_inst_asr, vb_generated_text=vb_generated_text, \\\n",
    "\t\t\t\t\t\t\tpredicted_objects=predicted_objects)\t\n",
    "\ttime_last_say = timei\n",
    "\tprint(prompt_obi)\n",
    "\tprint(\"############ OUTPUT FROM API ########\")\n",
    "\n",
    "\t# TODO: generate an answer using LLaVA\n",
    "\ttext = \"<placeholder returned text>\"\n",
    "\t\n",
    "\tprint(text)\n",
    "\tprint()\n",
    "\tprint()\n",
    "\n",
    "\treturn time_last_say, prompt_i, text\n",
    "\n",
    "\n",
    "def getInstruct(file_name, MTYPE, all_vid_path, out_path):\n",
    "\t############################################ import everything ############################################\n",
    "\t############################################ import everything ############################################\n",
    "\n",
    "\t### get recipe type\n",
    "\trecipe_type = file_name.split('_')[-1]\n",
    "\tprint(\"### RECIPE: \" + recipe_type)\n",
    "\n",
    "\t# import start and end time\n",
    "\twith open(os.path.join(all_vid_path, file_name, 'Video/VideoMpegTiming.txt')) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\tvid_start = int(lines[0][:-1])\n",
    "\tvid_end = int(lines[1][:-1])\n",
    "\tprint(\"Start/End Time:\\t\", vid_start, vid_end)\n",
    "\n",
    "\t# import steps\n",
    "\tin_step = []\n",
    "\twith open(os.path.join(all_vid_path, file_name,'StepDetection/StepDetection.txt')) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\tfor li in lines:\n",
    "\t\ttp = li[:-1].split('\\t')\n",
    "\t\ttp[0] = int(tp[0])\n",
    "\t\ttp[1] = int(tp[1])\n",
    "\t\tin_step.append(tp)\n",
    "\tprint(\"Num Steps:\\t\", len(in_step))\n",
    "\n",
    "\n",
    "\t# import instruct asr\n",
    "\tin_inst_asr = []\n",
    "\twith open(os.path.join(all_vid_path, file_name,'TextASR/InstructorAnnotations_intent.txt')) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\tfor li in lines:\n",
    "\t\ttp = li[:-1].split('\\t')\n",
    "\t\ttp[0] = int(tp[0])\n",
    "\t\ttp[1] = int(tp[1])\n",
    "\t\tin_inst_asr.append(tp)\n",
    "\tprint(\"Num Inst ASR:\\t\", len(in_inst_asr))\n",
    "\t\t\n",
    "\t# import user asr\n",
    "\tin_user_asr = []\n",
    "\twith open(os.path.join(all_vid_path, file_name,'TextASR/UserAnnotations_intent.txt')) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\tfor li in lines:\n",
    "\t\ttp = li[:-1].split('\\t')\n",
    "\t\ttp[0] = int(tp[0])\n",
    "\t\ttp[1] = int(tp[1])\n",
    "\t\tin_user_asr.append(tp)\n",
    "\tprint(\"Num User ASR:\\t\", len(in_user_asr))\n",
    "\n",
    "\t### import GT recipe\n",
    "\trecipe_name = os.path.join(name_li_path, \"recipe_\" + recipe_type + \".txt\")\n",
    "\tprompt_recipe = \"\"\n",
    "\twith open(recipe_name) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\tfor li in lines:\n",
    "\t\tprompt_recipe += li\n",
    "\n",
    "\n",
    "\t### Import video\n",
    "\tvideo = VideoFileClip(os.path.join(all_vid_path, file_name,\"Video/Video.mpeg\"))\n",
    "\taudio = video.audio\n",
    "\tnum_frames = int(video.fps * video.duration)\n",
    "\tframe_ratio = num_frames/(vid_end - vid_start)\n",
    "\tframes = video.iter_frames()\n",
    "\n",
    "\tprint(\"duration\\t\", str(video.duration))\n",
    "\tprint(\"num_frames\\t\", str(num_frames))\n",
    "\tprint()\n",
    "\n",
    "\n",
    "\t############################################ Model Specific Prep ############################################\n",
    "\t############################################ Model Specific Prep ############################################\n",
    "\t\n",
    "\t### Prepare Obj Detection\n",
    "\tif MTYPE == 'objDet':\n",
    "\t\tmodel_obj1, model_cb, model_hand, objs_pinwheel_out, pinwheel_dic_clean = prep_obj(recipe_type)\n",
    "\t\tegoModels = [model_obj1, model_cb, model_hand]\n",
    "\n",
    "\n",
    "\t############################################ Going through Frames ############################################\n",
    "\t############################################ Going through Frames ############################################\n",
    "\tlast_say_user = \"\"\n",
    "\tlast_say_inst = \"\"\n",
    "\ttime_last_say = 0\n",
    "\tchat_history = []\n",
    "\tobj_history = []\n",
    "\tobj_history_state_dic = {}\n",
    "\n",
    "\n",
    "\t### run detection model on each frame\n",
    "\tfor i, fra in enumerate(frames):\n",
    "\t\t# remove before start and after end\n",
    "\t\tif (in_step[0][2] == 'Start') and (i <= (in_step[0][1] - vid_start)*frame_ratio):\n",
    "\t\t\tcontinue\n",
    "\t\tif (in_step[-1][2] == 'Done') and (i >= (in_step[-1][0] - vid_start)*frame_ratio):\n",
    "\t\t\tbreak\n",
    "\t\ttimei = round(i/frame_ratio/1e7, 1)\n",
    "\t\tprompt_i = \"\"\n",
    "\t\tvb_generated_text = None\n",
    "\t\tpredicted_objects = None\n",
    "\t\tprompt_type3 = None\n",
    "\n",
    "\t\t# everytime inst talks\n",
    "\t\tsay_ins = parse_text_time(i, in_inst_asr, vid_start, frame_ratio)\n",
    "\t\tif (len(say_ins) != 0) and (say_ins[0] != last_say_inst):\n",
    "\t\t\tprompt_type3 = \"##### INSTRUCTOR PROMPT: \" + str(i) +  '/' + str(num_frames)\n",
    "\t\t\tprint(prompt_type3)\n",
    "\t\t\tlast_say_inst = say_ins[0]\n",
    "\t\t\tif MTYPE == 'objDet':\n",
    "\t\t\t\tpredicted_objects, obj_history, obj_history_state_dic = get_obj_states(fra, obj_history, \\\n",
    "\t\t\t\t\t\t\t\t\tobj_history_state_dic, egoModels, objs_pinwheel_out, pinwheel_dic_clean)\n",
    "\t\t\telif MTYPE == 'blip2':\n",
    "\t\t\t\tvb_generated_text = call_BLIP2(fra)\n",
    "\t\t\ttime_last_say, prompt_i, text = genAndCall(prompt_recipe, chat_history, timei, fill_user_asr=None, \\\n",
    "\t\t\t\t\t\t\t\t\t\tfill_inst_asr=last_say_inst, vb_generated_text=vb_generated_text, \\\n",
    "\t\t\t\t\t\t\t\t\t\tpredicted_objects=predicted_objects)\n",
    "\t\t\tchat_history.append([timei, \"You\", last_say_inst])\n",
    "\n",
    "\t\t\n",
    "\t\t# everytime user talks\n",
    "\t\tsay_usr = parse_text_time(i, in_user_asr, vid_start, frame_ratio)\n",
    "\t\tif (len(say_usr) != 0) and (say_usr[0] != last_say_user):\t\t\t\n",
    "\t\t\tprompt_type3 = \"##### USER PROMPT: \" + str(i) + '/' + str(num_frames)\n",
    "\t\t\tprint(prompt_type3)\n",
    "\t\t\tlast_say_user = say_usr[0]\n",
    "\t\t\tif MTYPE == 'objDet':\n",
    "\t\t\t\tpredicted_objects, obj_history, obj_history_state_dic = get_obj_states(fra, obj_history, \\\n",
    "\t\t\t\t\t\t\t\t\tobj_history_state_dic, egoModels, objs_pinwheel_out, pinwheel_dic_clean)\n",
    "\t\t\telif MTYPE == 'blip2':\n",
    "\t\t\t\tvb_generated_text = call_BLIP2(fra)\n",
    "\t\t\ttime_last_say, prompt_i, text = genAndCall(prompt_recipe, chat_history, timei, fill_user_asr=last_say_user, \\\n",
    "\t\t\t\t\t\t\t\t\tfill_inst_asr=None, vb_generated_text=vb_generated_text, \\\n",
    "\t\t\t\t\t\t\t\t\tpredicted_objects=predicted_objects)\n",
    "\t\t\tchat_history.append([timei, \"User\", last_say_user])\n",
    "\n",
    "\t\t\n",
    "\t\t\t# not talking for wait time\n",
    "\t\tif (prompt_i == \"\") and ((i/frame_ratio/1e7 - time_last_say) > time_wait):\n",
    "\t\t\tprompt_type3 = \"##### WAIT PROMPT: \" + str(i) + '/' + str(num_frames)\n",
    "\t\t\tprint(prompt_type3)\n",
    "\t\t\tif MTYPE == 'objDet':\n",
    "\t\t\t\tpredicted_objects, obj_history, obj_history_state_dic = get_obj_states(fra, obj_history, \\\n",
    "\t\t\t\t\t\t\t\t\tobj_history_state_dic, egoModels, objs_pinwheel_out, pinwheel_dic_clean)\n",
    "\t\t\telif MTYPE == 'blip2':\n",
    "\t\t\t\tvb_generated_text = call_BLIP2(fra)\n",
    "\t\t\ttime_last_say, prompt_i, text = genAndCall(prompt_recipe, chat_history, timei, fill_user_asr=None, \\\n",
    "\t\t\t\t\t\t\t\t\tfill_inst_asr=None, vb_generated_text=vb_generated_text, \\\n",
    "\t\t\t\t\t\t\t\t\tpredicted_objects=predicted_objects)\n",
    "\n",
    "\n",
    "\t\t# write prompts to file\n",
    "\t\tif prompt_i != \"\":\n",
    "\t\t\twith open(os.path.join(out_path, \"prompt_\" + file_name + \".txt\"), \"a\") as file1:\n",
    "\t\t\t\tfile1.writelines(\"##### FRAME: \" + str(i) + '/' + str(num_frames) + '\\n')\n",
    "\t\t\t\tfile1.writelines(prompt_i)\n",
    "\n",
    "\t\t\twith open(os.path.join(out_path, \"api_\" + file_name + \".txt\"), \"a\") as file2:\n",
    "\t\t\t\tfile2.writelines(\"\\n\\n\" + prompt_type3)\n",
    "\t\t\t\tfile2.writelines(\"\\n##### FRAME: \" + str(i) + '/' + str(num_frames) + '\\n')\n",
    "\t\t\t\tfile2.writelines(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(MTYPE, video_list, in_path, out_path):\n",
    "\t# open a list of file names\n",
    "\twith open(video_list) as f:\n",
    "\t\tlines = f.readlines()\n",
    "\n",
    "\t\t# go through each recording one by onne\n",
    "\t\tfor li in lines:\n",
    "\t\t\tprint(li[:-1])\n",
    "\t\t\tgetInstruct(li[:-1], MTYPE, in_path, out_path)\n",
    "\n",
    "main(\"lanOnly\", \"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
