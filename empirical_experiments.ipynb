{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d89e332-8f41-4711-8649-f9e5ac3aa0ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609598b0-4653-4b42-85ba-2a38a01e4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177fd0ff-6cd5-4fcc-9e01-b3063bbe70b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "print(torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "CACHE_DIR = \"/scratch/chaijy_root/chaijy0/sstorks/.cache/huggingface\"\n",
    "os.environ['HF_HOME'] = CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8388735e-8531-4f6d-a3fb-9426fd4871df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 30 17:03:17 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     On  | 00000000:1E:00.0 Off |                    0 |\n",
      "|  0%   34C    P0              56W / 300W |      7MiB / 46068MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1bf86-9398-4387-b285-efed1cbc2fa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CaptainCook4D Toy Experiments Empirical Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979217a-1884-47da-b647-ea40a36ec49b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9a6ded-f32b-4a0f-a73b-433faf4a09dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_DIR = \"/nfs/turbo/coe-chaijy-unreplicated/datasets/captaincook4d/data/captain_cook_4d/hololens/sync/pv\" # Directory containing CaptainCook4D mp4s\n",
    "ANNOTATIONS_DIR = \"/nfs/turbo/coe-chaijy-unreplicated/datasets/captaincook4d/annotations\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da263f28-4a27-4ced-a251-6bf10e3d71db",
   "metadata": {},
   "source": [
    "Boilerplate code to load video frames from video files (from GPT4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc4c178-6877-48b3-b63b-6dabba1694e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_video(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open video file\")\n",
    "    \n",
    "    return cap\n",
    "    # remember to call cap.release() later\n",
    "\n",
    "def extract_frames(cap, times):\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "    frames = []\n",
    "\n",
    "    for t in times:\n",
    "        frame_number = int(t * fps)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            # Convert to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)            \n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            print(f\"Warning: Frame at time {t} seconds could not be read.\")\n",
    "            frames.append(None)\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0b055-155e-4677-8dd4-88a534d6a36e",
   "metadata": {},
   "source": [
    "Other utils functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4d12f8-de7a-4660-8da5-10dc45d044ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_float_series(start, end, step):\n",
    "    # Ensure step is a positive float\n",
    "    step = abs(step)\n",
    "\n",
    "    # Initialize the series with the start value\n",
    "    series = [start]\n",
    "\n",
    "    # Generate numbers in the series\n",
    "    while start + step <= end:\n",
    "        start += step\n",
    "        series.append(start)\n",
    "\n",
    "    # Check if the end value is already in the series\n",
    "    if series[-1] != end:\n",
    "        series.append(end)\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b10717-ba26-4c79-8fd7-2e2ff9d77506",
   "metadata": {},
   "source": [
    "Data classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f053a3-7d66-45c1-ada0-2c9cc3ff28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "ERROR_CATEGORIES = json.load(open(os.path.join(ANNOTATIONS_DIR, \"annotation_json/error_category_idx.json\"), \"r\"))\n",
    "\n",
    "@dataclass\n",
    "class MistakeDetectionExample:\n",
    "     video_id: str\n",
    "     step_id: int\n",
    "     frames: list[Image]\n",
    "     action_description: str\n",
    "     mistake: bool\n",
    "     mistake_type: Optional[str] = None\n",
    "     mistake_description: Optional[str] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f74f1-7da4-48ed-8bc3-dcdc2fd8b97c",
   "metadata": {},
   "source": [
    "Gather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67479c4b-1d26-4899-9ccc-8b3a37799f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/335 [00:01<05:41,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 1\n",
      "Success examples: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/335 [00:01<04:42,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 3\n",
      "Success examples: 11\n",
      "Warning: Some error information discarded from only using the first annotated error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/335 [00:02<04:57,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 8\n",
      "Success examples: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/335 [00:05<08:12,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 8\n",
      "Success examples: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/335 [00:05<06:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 11\n",
      "Success examples: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/335 [00:06<05:07,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 12\n",
      "Success examples: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/335 [00:07<05:15,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some error information discarded from only using the first annotated error.\n",
      "Error examples: 17\n",
      "Success examples: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/335 [00:08<05:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error examples: 17\n",
      "Success examples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/335 [00:09<06:23,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected at least 20 positive and negative examples!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Pick a sample video from CaptainCook4D\n",
    "all_video_files = os.listdir(VIDEO_DIR)\n",
    "video_paths = [f for f in all_video_files if f.endswith('.mp4')]\n",
    "STEP_ANNOTATIONS = json.load(open(os.path.join(ANNOTATIONS_DIR, \"annotation_json/complete_step_annotations.json\"), \"r\"))\n",
    "ERROR_ANNOTATIONS = json.load(open(os.path.join(ANNOTATIONS_DIR, \"annotation_json/error_annotations.json\"), \"r\"))\n",
    "for error_annotation in ERROR_ANNOTATIONS:\n",
    "    video_id = error_annotation['recording_id']\n",
    "    STEP_ANNOTATIONS[video_id][\"steps_errors\"] = error_annotation[\"step_annotations\"]\n",
    "\n",
    "success_examples = []\n",
    "error_examples = []\n",
    "for sample_video_path in tqdm(video_paths):\n",
    "    sample_video_id = \"_\".join(sample_video_path.split('_')[:2])\n",
    "    sample_video_path = os.path.join(VIDEO_DIR, sample_video_path)\n",
    "    try:\n",
    "        sample_video = get_video(sample_video_path)\n",
    "    except:\n",
    "        print(f\"Warning: could not open video file: {sample_video_path}\")\n",
    "        continue\n",
    "\n",
    "    # Load step annotations for it and display precondition/effect frames\n",
    "    for step in STEP_ANNOTATIONS[sample_video_id][\"steps_errors\"]:\n",
    "        # Extract some keyframes for the action\n",
    "        step_duration = step['end_time'] - step['start_time']\n",
    "        step_id = int(step['step_id'])\n",
    "        \n",
    "        # Some steps are skipped\n",
    "        if step_duration < 0.1:\n",
    "            continue\n",
    "\n",
    "        adjusted_start = step['start_time'] + min(step_duration * 0.05, 0.5) # Adjust the start time to be later by a maximum of 0.5 seconds\n",
    "        adjusted_end = step['end_time'] - min(step_duration * 0.3, 3) # Adjust the end time to be earlier by a maximum of 3 seconds\n",
    "        SAMPLE_FREQUENCY = 4.0\n",
    "        times = generate_float_series(adjusted_start, adjusted_end, SAMPLE_FREQUENCY) # ultimately, we'll want to look at every image frame in some regular interval to determine if there's a mistake\n",
    "        frames = extract_frames(sample_video, times)\n",
    "        frames = [Image.fromarray(frame) for frame in frames]\n",
    "\n",
    "        verb, action_description = step['description'].split(\"-\")[0], \"-\".join(step['description'].split(\"-\")[1:])\n",
    "        \n",
    "        if \"errors\" in step and len(step[\"errors\"]) > 0:               \n",
    "            mistake_type = step['errors'][0][\"tag\"]\n",
    "            mistake_description = step['errors'][0]['description']\n",
    "            # altered_action_description = step['modified_description'] # NOTE: can use this later if needed\n",
    "            \n",
    "            # Start with only errors specific to a single step, not related to quantities\n",
    "            # Preparation error involves the wrong object(s)\n",
    "            # Technique error involves action being performed the wrong way\n",
    "            if mistake_type not in [\"Preparation Error\", \"Technique Error\"]:\n",
    "                continue\n",
    "            \n",
    "            if len(step['errors']) > 1:\n",
    "                print(\"Warning: Some error information discarded from only using the first annotated error.\")            \n",
    "            \n",
    "            error_examples.append(\n",
    "                MistakeDetectionExample(\n",
    "                    sample_video_id,\n",
    "                    step_id,\n",
    "                    frames,\n",
    "                    action_description,\n",
    "                    True,\n",
    "                    mistake_type,\n",
    "                    mistake_description\n",
    "                )\n",
    "            )\n",
    "            # pprint(error_examples[-1])\n",
    "        else:\n",
    "            success_examples.append(\n",
    "                MistakeDetectionExample(\n",
    "                    sample_video_id,\n",
    "                    step_id,\n",
    "                    frames,\n",
    "                    action_description,\n",
    "                    False\n",
    "                )\n",
    "            )        \n",
    "            # pprint(success_examples[-1])\n",
    "\n",
    "    if len(error_examples) >= 20 and len(success_examples) >= 20:\n",
    "        print(\"Collected at least 20 positive and negative examples!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Error examples:\", len(error_examples))\n",
    "        print(\"Success examples:\", len(success_examples))\n",
    "\n",
    "    sample_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd334845-fe6e-4054-9a58-452ca5162f50",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5ba9b-72b1-4c65-b1c6-8f7a1f8fa89d",
   "metadata": {},
   "source": [
    "## Step 1: VQG with LLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19146ad2-de89-4e12-b0f3-e12dc5f7cb14",
   "metadata": {},
   "source": [
    "Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e252bb11-0097-4112-ae3b-2ffa1893a71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae53f669074942d2b1df6088fdad2c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "LM_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
    "model = pipeline(\"text-generation\", model=LM_NAME, token=\"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\", model_kwargs= {\"load_in_8bit\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5d51a-4e59-4f84-87eb-5aeaf148de2d",
   "metadata": {},
   "source": [
    "Load recipe steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f73e44-33ad-42aa-87c8-b6043c172f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Pour 1 egg into the ramekin cup',\n",
      " 2: 'Place the egg from the cup over the lettuce',\n",
      " 3: 'Coat a 6-oz. ramekin cup with cooking spray',\n",
      " 4: 'Microwave the ramekin cup uncovered on high for 30 seconds',\n",
      " 5: 'sprinkle 1 tablespoon of cheese on cup',\n",
      " 6: 'Top cup with 1 tablespoon of salsa',\n",
      " 7: 'replace the top of the English muffin',\n",
      " 8: 'Continue to Microwave for 15-30 more seconds or until the egg is almost '\n",
      "    'set',\n",
      " 9: 'Line the bottom piece of the English muffin with lettuce',\n",
      " 10: 'Microwave just until cheese melts, about 10 seconds',\n",
      " 11: 'stir the ramekin cup',\n",
      " 12: 'Cut the English muffin into two pieces with a knife',\n",
      " 14: 'Peel 1 garlic clove',\n",
      " 15: 'Pour the sauces over the meatballs',\n",
      " 16: 'Cut 1/8 garlic clove',\n",
      " 17: 'Peel one medium onion',\n",
      " 18: 'Stir the contents in the microwave with a spoon',\n",
      " 19: 'Slice 1/8 medium onion',\n",
      " 20: 'Microwave the plate, covered, on high for 1.5 minutes',\n",
      " 21: 'Place 5 meatballs in a Microwave-safe plate',\n",
      " 22: 'Cut 1/4 medium carrot into short, thin strips',\n",
      " 23: 'Mix 1/4 cup sweet-and-sour sauce and 1/2 teaspoon soy sauce in a small '\n",
      "     'bowl',\n",
      " 24: 'Top the plate with the carrots, onion, garlic and 1/4 tsp pepper powder',\n",
      " 25: 'Microwave for 1 more minute',\n",
      " 26: 'Mince 1/8 garlic clove',\n",
      " 27: 'Cut onion into two pieces',\n",
      " 28: 'Measure 1/8 teaspoon of salt and add it to the mug',\n",
      " 29: 'Sprinkle dried Italian herbs inside the mug',\n",
      " 30: 'Take 1 tablespoon of marinara sauce',\n",
      " 31: 'spread marinara sauce around the surface of the batter',\n",
      " 32: 'Microwave for 1 minute 20 seconds, or until it rises and the toppings '\n",
      "     'are bubbling',\n",
      " 33: 'Measure 4 tablespoons of flour and add it to the mug',\n",
      " 34: '1 tablespoon of olive oil to the mug',\n",
      " 35: 'Measure 1/16 teaspoon of baking soda and add it to the mug',\n",
      " 36: 'Take a microwavable mug',\n",
      " 37: 'Mix the contents of the mug thoroughly. (There might be some lumps, but '\n",
      "     'that is ok.)',\n",
      " 38: 'Stir the contents in the mug well',\n",
      " 39: 'Sprinkle 1 generous tablespoon of mozzarella cheese on top of the sauce',\n",
      " 40: 'Measure 1/8 teaspoon of baking powder and add it to the mug',\n",
      " 41: 'Add in 3 tablespoons of milk to the mug',\n",
      " 42: 'Mix in the flavour packet to the bowl',\n",
      " 43: 'Stir noodles with a spoon or fork until the flavouring dissolves',\n",
      " 44: 'Remove the noodles from the package(Break Noodles / Keep them as a '\n",
      "     'block)',\n",
      " 45: 'Microwave the ramen for 4 minutes',\n",
      " 46: 'slice 1/4 medium onion into pieces',\n",
      " 47: 'Peel 1 medium onion',\n",
      " 48: 'Let the noodles sit for about 1 minute after the microwave stops',\n",
      " 49: 'Cover with a lid (or paper towel) to prevent splattering',\n",
      " 50: 'Add basil to the bowl',\n",
      " 51: 'Chop 1 garlic clove on a cutting board',\n",
      " 52: 'Add the noodles to the bowl',\n",
      " 53: 'Add chopped cilantro to the bowl',\n",
      " 54: 'Put all the Vegetables in a microwave-safe bowl',\n",
      " 55: 'cover the noodles with water',\n",
      " 56: 'Wait about 30 seconds for the coffee to bloom. (You will see small '\n",
      "     'bubbles or foam on the coffee grounds during this step.)',\n",
      " 57: 'Pour a small amount of water into the filter to wet the grounds',\n",
      " 58: 'Transfer the grounds to the filter cone',\n",
      " 59: 'spread open filter in dripper to create a cone',\n",
      " 60: 'Place the paper filter in the dripper',\n",
      " 61: 'Slowly pour the rest of the water over the grounds in a circular motion. '\n",
      "     'Do not overfill beyond the top of the paper filter',\n",
      " 62: 'Prepare the filter insert by folding the paper filter in half to create '\n",
      "     'a semi-circle, and in half again to create a quarter-circle',\n",
      " 63: 'Discard the paper filter and coffee grounds',\n",
      " 64: 'Boil the water. (While the water is boiling, assemble the filter cone)',\n",
      " 65: 'Weigh the coffee beans (0.8oz-0.12 oz)',\n",
      " 66: 'Let the coffee drain completely into the mug before removing the dripper',\n",
      " 67: 'Grind the coffee beans until the coffee grounds are the consistency of '\n",
      "     'coarse sand, about 20 seconds',\n",
      " 68: 'Measure 12 ounces of cold water',\n",
      " 69: 'Place the dripper on top of a coffee mug',\n",
      " 70: 'transfer water to a kettle',\n",
      " 71: 'Once the water has boiled, check the temperature of the water. (The '\n",
      "     'water should be between 195-205 degrees Fahrenheit or between 91-96 '\n",
      "     'degrees Celsius. If the water is too hot, let it cool briefly.)',\n",
      " 72: 'Whisk the egg',\n",
      " 73: 'Microwave for 3 minutes, stirring in between',\n",
      " 74: 'Add 1/2 tbsp sweet and sour sauce to the bowl',\n",
      " 75: 'Sprinkle 1 tbsp shredded cheddar cheese on top of the egg',\n",
      " 76: 'Mix the contents of the bowl well',\n",
      " 77: 'Extract and add contents of an egg to a microwave-safe bowl',\n",
      " 78: 'Roll the tortilla from one end to another into a log shape, about 1.5 '\n",
      "     'inches thick. Roll it tight enough to prevent gaps but not so tight that '\n",
      "     'the filling leaks',\n",
      " 79: 'Pour egg mixture on top of the tortilla',\n",
      " 80: 'Add 1 tbsp salsa to the bowl',\n",
      " 81: 'Place 8 inch tortilla on a cutting board',\n",
      " 82: 'Sprinkle oregano in the bowl',\n",
      " 83: 'Heat the contents of the mug for 1 minute and serve',\n",
      " 84: 'Add 1/5 teaspoon cinnamon to the mug',\n",
      " 85: 'Mix the contents of the mug',\n",
      " 87: 'Add 1 teaspoon of white sugar to the mug',\n",
      " 88: 'Fill a microwave-safe mug with skimmed milk',\n",
      " 89: 'Microwave the contents of the mug for 1 minute',\n",
      " 90: 'Add 2 pieces of chocolate to the mug',\n",
      " 91: 'Microwave on high for 90 seconds until the egg is cooked through',\n",
      " 92: 'add bread pieces to the egg mixture in the mug, pressing the bread down '\n",
      "     'into the egg',\n",
      " 93: 'stir the mug',\n",
      " 94: 'In a large mug, melt 1 tablespoon of softened butter in the microwave '\n",
      "     'for about 30 seconds',\n",
      " 95: 'Sprinkle 1/4 teaspoon cinnamon over the egg',\n",
      " 96: 'cut the contents on plate, and serve',\n",
      " 97: \"Put the mug's contents on a plate\",\n",
      " 98: 'Roll the butter around in the mug to coat it',\n",
      " 99: 'Cut or tear 1 slices of bread into bite-size pieces',\n",
      " 100: 'Add 1/4 teaspoon vanilla extract to the mug',\n",
      " 101: 'In the mug, whisk one egg with a fork until well blended',\n",
      " 102: 'Continue slicing with floss to create 1 more pinwheel',\n",
      " 103: 'Discard ends of the tortilla',\n",
      " 104: 'Clean the knife by wiping with a paper towel',\n",
      " 105: \"Cross the floss's two ends over the tortilla roll's top\",\n",
      " 106: 'Slide floss under the tortilla, perpendicular to the length of the roll',\n",
      " 107: 'Spread jelly over the nut butter',\n",
      " 108: 'pull the floss ends in opposite directions to slice',\n",
      " 109: 'Place the pinwheels on a plate',\n",
      " 110: 'Secure the rolled tortilla by inserting 5 toothpicks about 1 inch apart',\n",
      " 111: 'Use the knife to scoop jelly from the jar',\n",
      " 112: 'Spread nut butter onto the tortilla, leaving 1/2-inch uncovered at the '\n",
      "      'edges',\n",
      " 113: 'Use a butter knife to scoop nut butter from the jar',\n",
      " 114: 'Trim the ends of the tortilla roll with the butter knife, leaving 1/2 '\n",
      "      'inch margin between the last toothpick and the end of the roll',\n",
      " 115: 'Place 8-inch flour tortilla on cutting board',\n",
      " 116: 'Roll the tortilla from one end to the other into a log shape, about 1.5 '\n",
      "      'inches thick. Roll it tight enough to prevent gaps, but not so tight '\n",
      "      'that the filling leaks',\n",
      " 117: 'Place the floss halfway between toothpicks',\n",
      " 118: 'Clean the knife by wiping it with a paper towel',\n",
      " 119: 'Slice one tomato into about 1/2 inch thick slices',\n",
      " 120: 'Place the thick slices of tomatoes on a platter, ensuring they only '\n",
      "      'make a single layer',\n",
      " 121: 'Add a drizzle of extra-virgin olive oil, about 1 tablespoon, over the '\n",
      "      'entire platter',\n",
      " 122: 'gently dry it with a paper/tea towel',\n",
      " 123: 'Season the tomato slices with salt',\n",
      " 124: 'Sprinkle mozzarella cheese on top of the tomato throughout the platter',\n",
      " 125: 'Rinse a tomato',\n",
      " 126: 'Season platter with 1/4 teaspoon black pepper',\n",
      " 127: 'Garnish platter with italian seasoning',\n",
      " 128: 'add lime juice to the bowl',\n",
      " 129: 'Measure 2 cups of frozen corn',\n",
      " 130: '1 teaspoon of pepper powder to the bowl',\n",
      " 131: 'Extract lime juice from 1/3 lime',\n",
      " 132: 'Add the corn into a microwave-safe bowl',\n",
      " 133: 'Microwave the corn for 2 minutes',\n",
      " 134: 'Microwave the corn for 3 more minutes',\n",
      " 135: 'then stir the bowl',\n",
      " 136: 'Add 1 teaspoon salt to the bowl',\n",
      " 137: 'Thaw the frozen corn by putting it in a sieve and running it under cold '\n",
      "      'water',\n",
      " 138: 'Add 1 teaspoon of softened butter',\n",
      " 139: 'Add 1/4 tsp mustard to the pan',\n",
      " 140: 'mince the garlic',\n",
      " 141: '1/2 tsp cumin seeds to the pan',\n",
      " 142: 'Add tomato puree to the pan',\n",
      " 143: 'Take the pan off the heat',\n",
      " 144: 'Mix well tomato puree with contents in the pan',\n",
      " 145: 'Peel 4 large garlic cloves',\n",
      " 146: '1/2 tsp salt to the pan',\n",
      " 147: 'Add 2 tbsp red chili powder to the pan',\n",
      " 148: 'Saute the garlic for 2-3 minutes',\n",
      " 149: 'Take 1 tomato',\n",
      " 150: 'puree tomatoes without any water in a blender/mixer',\n",
      " 151: 'Lower the heat',\n",
      " 152: 'When mustard and cumin seeds begin to sizzle, add minced garlic',\n",
      " 153: 'Allow the mixture to simmer over low heat for 5 minutes or until the '\n",
      "      'mixture becomes thick',\n",
      " 154: 'Heat 3 tbsp oil in a pan over medium heat',\n",
      " 155: 'Chop tomato roughly (anysize chunks are fine)',\n",
      " 156: 'Transfer it to a serving bowl',\n",
      " 157: 'mix well contents of the pan',\n",
      " 158: 'Chop 1 tsp cilantro',\n",
      " 159: 'Whisk the egg mixture in the bowl',\n",
      " 160: 'Add garlic to the pan',\n",
      " 161: 'Chop 1 green chilli',\n",
      " 162: 'Add chilli to the pan',\n",
      " 163: 'Chop 1/4 medium onion',\n",
      " 164: 'add 1/3 tsp salt to the bowl',\n",
      " 165: 'Cook for 1 minute, mixing everything',\n",
      " 166: 'Saute the onions on medium heat until they are soft and translucent',\n",
      " 167: 'Crack one egg in the bowl',\n",
      " 168: 'Add 1/8 tsp of turmeric to the pan',\n",
      " 169: 'Chop 1/4 tomato',\n",
      " 170: 'Cook covered for 1 minute or until the tomatoes soften',\n",
      " 171: 'Keep mixing with a spatula for 3 minutes or until the eggs are almost '\n",
      "      'cooked',\n",
      " 172: 'Slowly pour the whisked eggs into the pan',\n",
      " 173: 'Heat 2 tbsp oil in a heavy-bottomed or nonstick pan on medium heat',\n",
      " 174: 'Garnish with 1 tbsp chopped cilantro and serve',\n",
      " 175: 'Add tomatoes to the pan',\n",
      " 176: 'Peel 2 garlic cloves',\n",
      " 177: 'add 1 tbsp milk to the bowl',\n",
      " 178: 'add 1/3 tsp salt to the pan',\n",
      " 179: 'add chopped onions to the pan',\n",
      " 180: 'Mince peeled garlic cloves',\n",
      " 181: '1/4 teaspoon of red chilli powder to the bowl',\n",
      " 182: 'peel the cucumber',\n",
      " 183: 'In a mixing bowl, whisk 1 cup of chilled curd until smooth. Use fresh '\n",
      "      'homemade or packaged curd',\n",
      " 184: '1/4 teaspoon salt to the bowl',\n",
      " 185: 'chop or grate the cucumber',\n",
      " 186: 'Combine all the ingredients in the bowl',\n",
      " 187: 'add 1 tablespoon of chopped cilantro leaves to the bowl',\n",
      " 188: 'Add 1 teaspoon of cumin powder to the bowl',\n",
      " 189: 'Rinse 1 medium sized cucumber',\n",
      " 190: 'Add the chopped or grated cucumber to the whisked curd',\n",
      " 191: '1/2 teaspoon of chaat masala powder to the bowl',\n",
      " 192: 'Cook for 2 minutes or until the zoodles are done',\n",
      " 193: '1/6 cup grated parmesan cheese',\n",
      " 194: 'pepper to taste',\n",
      " 195: 'Top with more parmesan if desired',\n",
      " 196: 'Heat a large pan on medium heat',\n",
      " 197: 'Remove from heat',\n",
      " 198: 'season with salt',\n",
      " 199: 'Add 1 large minced garlic cloves to the pan',\n",
      " 200: 'Peel 1 garlic cloves',\n",
      " 201: 'Add the zucchini noodles',\n",
      " 202: 'Cook garlic until fragrant (about 1 minutes). Be careful not to burn '\n",
      "      'garlic',\n",
      " 203: 'Spiralize 1 medium zucchini into thin noodles using a spiralizer',\n",
      " 204: 'Melt 1 tablespoons of softened butter',\n",
      " 205: 'pat rinsed mushrooms dry with a paper towel',\n",
      " 206: 'Rinse 3 mushrooms under cold water',\n",
      " 207: 'cook the pan, often stirring, for 1 minute',\n",
      " 208: 'Once the pan is hot, add the mushrooms',\n",
      " 209: 'Add chopped shallot to the pan',\n",
      " 210: 'Slice the mushrooms',\n",
      " 211: 'mince garlic cloves',\n",
      " 212: 'Chop 1 shallot',\n",
      " 213: 'cook for 3-5 minutes, stirring often, until mushrooms start to soften '\n",
      "      'and brown',\n",
      " 214: 'Pull out mushroom stems',\n",
      " 215: 'Heat 1 tbsp olive oil in a large skillet over medium-high heat',\n",
      " 216: 'Transfer the contents of the pan to a serving dish',\n",
      " 217: '1/4 tbsp balsamic vinegar to the pan',\n",
      " 218: 'Add 2 cloves of minced garlic to the pan',\n",
      " 219: 'pepper on pan to taste',\n",
      " 220: 'Season pan with salt',\n",
      " 221: '1/2 tsp baking powder to a blender',\n",
      " 222: 'Serve the pancakes with chopped strawberries',\n",
      " 223: 'Melt a small knob of butter in a non-stick frying pan over low-medium '\n",
      "      'heat',\n",
      " 224: 'splash maple syrup on plate',\n",
      " 225: 'Add 1 banana to a blender',\n",
      " 226: 'Cook for 1 min or until the tops start to bubble',\n",
      " 227: 'blitz the blender for 20 seconds',\n",
      " 228: 'Flip the pancakes with a fork or a fish slice spatula',\n",
      " 229: '1 egg to a blender',\n",
      " 230: 'cook for 20-30 seconds more',\n",
      " 231: 'Pour three little puddles straight from the blender into the frying pan',\n",
      " 232: '1 heaped tbsp flour to a blender',\n",
      " 233: 'Chop 1 strawberry',\n",
      " 234: 'Transfer to a plate',\n",
      " 235: 'Heat 1 tbsp oil in a non-stick frying pan',\n",
      " 236: 'put tomatoes on a serving plate',\n",
      " 237: 'Chop 2 tbsp cilantro',\n",
      " 238: 'stir gently with a wooden spoon so the egg that sets on the base of the '\n",
      "      'pan moves to enable the uncooked egg to flow into the space',\n",
      " 239: 'crack one egg in a bowl',\n",
      " 240: 'cook the tomatoes cut-side down until they start to soften and colour',\n",
      " 241: 'Pour the egg mixture into the pan',\n",
      " 242: 'add the chopped cilantro to the bowl',\n",
      " 243: 'Transfer omelette to the plate and serve with the tomatoes',\n",
      " 244: 'Scoop the tomatoes from the pan',\n",
      " 245: \"Stop stirring when it's nearly cooked to allow it to set into an \"\n",
      "      'omelette',\n",
      " 246: 'Cut tomato into two pieces',\n",
      " 247: 'Take a tomato',\n",
      " 248: 'Beat the contents of the bowl',\n",
      " 249: '1/2 tsp ground black pepper to the bowl',\n",
      " 250: 'Add 1/8 cup soy sauce to the bowl',\n",
      " 251: 'Set aside the sauce mixture',\n",
      " 252: 'Add 1 tablespoon honey to the bowl',\n",
      " 253: 'cook, stirring often, for 4 minutes. If the pan gets too hot on '\n",
      "      'medium-high, turn the heat down to medium',\n",
      " 254: 'Add 1 teaspoon cornstarch to the bowl',\n",
      " 255: 'Add 2 cloves minced garlic to the bowl',\n",
      " 256: 'Pour the sauce into the skillet',\n",
      " 257: 'Peel 2 cloves of garlic',\n",
      " 258: 'add sliced mushrooms to the skillet',\n",
      " 259: 'slice mushrooms',\n",
      " 260: 'Whisk the contents of bowl',\n",
      " 261: 'Add bell pepper to the skillet',\n",
      " 262: 'mince garlic',\n",
      " 263: 'slice 1/3 of the bell pepper',\n",
      " 264: 'cook, stirring, for 1 minute until the sauce thickens',\n",
      " 265: 'Add broccoli to the skillet',\n",
      " 266: 'Heat 2 tablespoons olive oil in a skillet over medium-high heat',\n",
      " 267: 'Add 1/2 tablespoon minced ginger to the bowl',\n",
      " 268: 'Add 1/8 teaspoon black pepper to the bowl',\n",
      " 269: 'Add 1/6 cup water the bowl',\n",
      " 270: 'Take 2 cremini mushrooms',\n",
      " 271: 'Take 1 bell pepper',\n",
      " 272: 'Whisk the sauce again to recombine the ingredients',\n",
      " 273: 'Take 5 in number broccoli florets',\n",
      " 274: 'continue cooking, stirring often, for 2-3 minutes, until vegetables are '\n",
      "      'crisp-tender',\n",
      " 275: 'Cut 1/4 block or 3 ounces of fresh tofu into large cubes (about 1 in x '\n",
      "      '1 in)',\n",
      " 276: 'Turn on the heat to medium',\n",
      " 277: 'drizzle 1 tablespoon soy sauce (watch for spitting) on the pan',\n",
      " 278: 'drizzle with the 1 tablespoons sesame oil on the pan',\n",
      " 279: 'add the tofu cubes to the pan',\n",
      " 280: 'Briefly remove the pan from the heat to reduce spitting',\n",
      " 281: 'flip tofu on the pan',\n",
      " 282: 'Briefly remove from the heat again',\n",
      " 283: 'Transfer to a serving dish',\n",
      " 284: 'Return to low heat',\n",
      " 285: 'Flip the tofu with tongs',\n",
      " 286: 'add 1/4 tsp salt to the pan',\n",
      " 287: 'Return the heat to medium',\n",
      " 288: 'cook pan for 2 minutes until the colour is darkened',\n",
      " 289: 'cook pan for 2 minutes',\n",
      " 290: 'cook until tofu turns brown',\n",
      " 291: 'Add 1 tablespoon of olive oil to a non-stick pan',\n",
      " 292: 'Cook 5 to 6 minutes until tofu cubes are lightly browned on the bottom',\n",
      " 293: 'pat tofu dry with a towel',\n",
      " 294: 'Whisk batter until no lumps remain',\n",
      " 295: 'then carefully remove the paper liner',\n",
      " 296: '2 tbsp water to the bowl',\n",
      " 297: '1.5 tbsp sugar to the mixing bowl',\n",
      " 298: 'While the cake is cooling, prepare to pipe the frosting. Scoop 4 '\n",
      "      'spoonfuls of chocolate frosting into a zip-top bag',\n",
      " 299: 'Measure and add 2 tbsp flour to the mixing bowl',\n",
      " 300: 'Measure and add 2 tsp vegetable oil to the bowl',\n",
      " 301: 'Set aside the lined mug',\n",
      " 302: 'Squeeze the frosting through the opening to apply small dollops of '\n",
      "      'frosting to the plate in a circle around the base of the cake',\n",
      " 303: 'Place the paper cupcake liner inside the mug',\n",
      " 304: '1/4 tsp baking powder to the bowl',\n",
      " 305: 'Allow to cool until it is no longer hot to the touch',\n",
      " 306: 'Use scissors to cut one corner from the bag to create a small opening '\n",
      "      '1/4 inch in diameter',\n",
      " 307: 'Pour batter into prepared mug',\n",
      " 308: 'Whisk to combine mixture of flour, sugar and baking powder in the bowl',\n",
      " 309: 'Invert the mug to release the cake onto a plate',\n",
      " 310: 'a pinch of salt to the mixing bowl',\n",
      " 311: 'seal zip top bag, removing as much air as possible',\n",
      " 312: 'Microwave the mug and batter on high power for 60 seconds. Check if the '\n",
      "      'cake is done by inserting and toothpick into the center of the cake and '\n",
      "      'then removing it. If wet batter clings to the toothpick, microwave for '\n",
      "      'an additional 5 seconds. If the toothpick comes out clean, continue',\n",
      " 313: '1/4 tsp vanilla extract to the bowl',\n",
      " 314: 'add 1/2 tbsp softened butter to the bowl',\n",
      " 315: 'Add 1/4 teaspoon salt to the bowl',\n",
      " 316: 'Add 1/3 cup cheddar cheese to a microwave-safe cup',\n",
      " 317: 'Mix the cheese and red bell pepper in the bowl',\n",
      " 318: 'Microwave the bowl, covered, for 2 minutes',\n",
      " 319: 'Add 1/4 teaspoon pepper to the bowl',\n",
      " 320: 'Add 1 tablespoons of water to the bowl',\n",
      " 321: 'Chop 1/4 red bell pepper into tiny bits',\n",
      " 322: 'Place the chopped pepper in the microwave-safe bowl',\n",
      " 323: 'Melt the cheese by microwaving cup for 30 sec. (Check after 30 seconds '\n",
      "      'and microwave for 10 seconds more if needed)',\n",
      " 324: 'Mix all the ingredients of the bowl well',\n",
      " 325: 'place avocado slices on each leaf',\n",
      " 326: 'season 1/4 tsp pepper on the bowl',\n",
      " 327: '1/4 cup mayonnaise to the bowl',\n",
      " 328: 'drain excess water from can',\n",
      " 329: 'Lay out 2 large lettuce leaves',\n",
      " 330: 'Roll up the lettuce wraps',\n",
      " 331: 'Mix the contents of the bowl',\n",
      " 332: 'top lettuce leaves with the tuna mixture',\n",
      " 333: 'add chopped scallion to the bowl',\n",
      " 334: 'Add 1 can drained tuna to the bowl',\n",
      " 335: 'Take 1 ripe avocado',\n",
      " 336: 'Open a can of tuna',\n",
      " 337: 'secure the wrap with a toothpick',\n",
      " 338: 'Season bowl with 1/4 tsp salt',\n",
      " 339: '1 tsp Sriracha sauce to the bowl',\n",
      " 340: 'Chop 1 scallion',\n",
      " 341: 'cut avocado into thin slices',\n",
      " 342: '1/8 cup shredded mozzarella to a bowl',\n",
      " 343: '1/4 tsp salt to a bowl',\n",
      " 344: 'Slice two 1/2 inch thick rounds from a baguette (slice slanted)',\n",
      " 345: 'Spoon the mixture from the bowl onto the bread',\n",
      " 346: '1/4 tsp pepper to a bowl',\n",
      " 347: '1/16 cup basil to a bowl',\n",
      " 348: 'Combine the contents of the bowl',\n",
      " 349: 'Brush 2 slices of baguette with olive oil on both sides',\n",
      " 350: 'Cut 1/4 cup of cherry tomatoes into halves',\n",
      " 351: 'In a bowl, add the cut cherry tomatoes',\n",
      " 352: 'Toast both sides of the slices on the pan for 2 to 3 minutes until '\n",
      "      'lightly charred and crispy and transfer the slices to a plate'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "RECIPE_STEPS = json.load(open(os.path.join(ANNOTATIONS_DIR, \"annotation_json/step_idx_description.json\"), \"r\"))\n",
    "RECIPE_STEPS = {int(k): \"-\".join(v.split(\"-\")[1:]).strip() for k, v in RECIPE_STEPS.items()}\n",
    "\n",
    "pprint(RECIPE_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1a4b2-ec0d-4679-9515-53a146c72403",
   "metadata": {},
   "source": [
    "Parse noun phrases from steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5af827d2-e9cf-4ff6-86df-0e254b35c5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['1 egg', 'the ramekin cup'],\n",
      " 2: ['the egg', 'the cup', 'the lettuce'],\n",
      " 3: ['a 6-oz. ramekin cup', 'cooking spray'],\n",
      " 4: ['the ramekin cup', '30 seconds'],\n",
      " 5: ['1 tablespoon', 'cheese', 'cup'],\n",
      " 6: ['Top cup', '1 tablespoon', 'salsa'],\n",
      " 7: ['the top', 'the English muffin'],\n",
      " 8: ['15-30 more seconds', 'the egg'],\n",
      " 9: ['the bottom piece', 'the English muffin', 'lettuce'],\n",
      " 10: ['Microwave', 'cheese melts'],\n",
      " 11: ['the ramekin cup'],\n",
      " 12: ['the English muffin', 'two pieces', 'a knife'],\n",
      " 14: ['Peel 1 garlic clove'],\n",
      " 15: ['the sauces', 'the meatballs'],\n",
      " 16: ['1/8 garlic clove'],\n",
      " 17: ['one medium onion'],\n",
      " 18: ['the contents', 'the microwave', 'a spoon'],\n",
      " 19: ['Slice 1/8 medium onion'],\n",
      " 20: ['the plate', '1.5 minutes'],\n",
      " 21: ['Place', '5 meatballs', 'a Microwave-safe plate'],\n",
      " 22: ['Cut 1/4 medium carrot', 'short, thin strips'],\n",
      " 23: ['Mix 1/4 cup sweet-and-sour sauce',\n",
      "      '1/2 teaspoon soy sauce',\n",
      "      'a small bowl'],\n",
      " 24: ['the plate', 'the carrots', 'onion', 'garlic', '1/4 tsp pepper powder'],\n",
      " 25: ['Microwave', '1 more minute'],\n",
      " 26: ['Mince 1/8 garlic clove'],\n",
      " 27: ['onion', 'two pieces'],\n",
      " 28: ['Measure 1/8 teaspoon', 'salt', 'the mug'],\n",
      " 29: ['dried Italian herbs', 'the mug'],\n",
      " 30: ['1 tablespoon'],\n",
      " 31: ['marinara', 'the surface', 'the batter'],\n",
      " 32: ['Microwave', '1 minute', '20 seconds', 'the toppings'],\n",
      " 33: ['Measure', '4 tablespoons', 'flour', 'the mug'],\n",
      " 34: ['1 tablespoon', 'olive oil', 'the mug'],\n",
      " 35: ['Measure', '1/16 teaspoon', 'soda', 'the mug'],\n",
      " 36: ['a microwavable mug'],\n",
      " 37: ['the contents', 'the mug', 'some lumps'],\n",
      " 38: ['the contents', 'the mug'],\n",
      " 39: ['1 generous tablespoon', 'mozzarella cheese', 'top', 'the sauce'],\n",
      " 40: ['Measure 1/8 teaspoon', 'powder', 'the mug'],\n",
      " 41: ['3 tablespoons', 'milk', 'the mug'],\n",
      " 42: ['the flavour packet', 'the bowl'],\n",
      " 43: ['noodles', 'a spoon'],\n",
      " 44: ['the noodles', 'the package(Break', 'Noodles', 'them', 'a block'],\n",
      " 45: ['the ramen', '4 minutes'],\n",
      " 46: ['slice 1/4 medium onion', 'pieces'],\n",
      " 47: ['Peel 1 medium onion'],\n",
      " 48: ['the noodles', 'about 1 minute', 'the microwave'],\n",
      " 49: ['a lid (or paper towel', 'splattering'],\n",
      " 50: ['basil', 'the bowl'],\n",
      " 51: ['Chop 1 garlic clove', 'a cutting board'],\n",
      " 52: ['the noodles', 'the bowl'],\n",
      " 53: ['cilantro', 'the bowl'],\n",
      " 54: ['all the Vegetables', 'a microwave-safe bowl'],\n",
      " 55: ['the noodles', 'water'],\n",
      " 56: ['the coffee', 'small bubbles', 'foam', 'the coffee grounds'],\n",
      " 57: ['a small amount', 'water', 'the filter', 'the grounds'],\n",
      " 58: ['the grounds', 'the filter cone'],\n",
      " 59: ['open filter', 'a cone'],\n",
      " 60: ['the paper filter', 'the dripper'],\n",
      " 61: ['the rest',\n",
      "      'the water',\n",
      "      'the grounds',\n",
      "      'a circular motion',\n",
      "      'the top',\n",
      "      'the paper filter'],\n",
      " 62: ['the paper filter', 'half', '-', 'circle', 'half', 'a quarter-circle'],\n",
      " 63: ['Discard the paper filter and coffee grounds'],\n",
      " 64: ['Boil', 'the water', 'the water', 'the filter cone'],\n",
      " 65: ['the coffee beans', '0.8oz-0.12'],\n",
      " 66: ['the coffee', 'the mug', 'the dripper'],\n",
      " 67: ['the coffee beans',\n",
      "      'the coffee grounds',\n",
      "      'the consistency',\n",
      "      'coarse sand'],\n",
      " 68: ['Measure', '12 ounces', 'cold water'],\n",
      " 69: ['the dripper', 'top', 'a coffee mug'],\n",
      " 70: ['water', 'a kettle'],\n",
      " 71: ['the water',\n",
      "      'the temperature',\n",
      "      'the water',\n",
      "      'The water',\n",
      "      '195-205 degrees',\n",
      "      'Celsius',\n",
      "      'the water'],\n",
      " 72: ['the egg'],\n",
      " 73: ['Microwave', '3 minutes'],\n",
      " 74: ['1/2 tbsp sweet and sour sauce', 'the bowl'],\n",
      " 75: ['Sprinkle 1 tbsp shredded cheddar cheese', 'top', 'the egg'],\n",
      " 76: ['the contents', 'the bowl'],\n",
      " 77: ['Extract', 'contents', 'an egg', 'a microwave-safe bowl'],\n",
      " 78: ['the tortilla',\n",
      "      'one end',\n",
      "      'another',\n",
      "      'a log shape',\n",
      "      'gaps',\n",
      "      'the filling leaks'],\n",
      " 79: ['egg mixture', 'top', 'the tortilla'],\n",
      " 80: ['1 tbsp', 'the bowl'],\n",
      " 81: ['Place 8 inch tortilla', 'a cutting board'],\n",
      " 82: ['the bowl'],\n",
      " 83: ['the contents', 'the mug', '1 minute'],\n",
      " 84: ['Add 1/5 teaspoon cinnamon', 'the mug'],\n",
      " 85: ['the contents', 'the mug'],\n",
      " 87: ['1 teaspoon', 'white sugar', 'the mug'],\n",
      " 88: ['a microwave-safe mug', 'skimmed milk'],\n",
      " 89: ['the contents', 'the mug', '1 minute'],\n",
      " 90: ['2 pieces', 'chocolate', 'the mug'],\n",
      " 91: ['Microwave', '90 seconds', 'the egg'],\n",
      " 92: ['bread pieces', 'the egg mixture', 'the mug', 'the bread', 'the egg'],\n",
      " 93: ['the mug'],\n",
      " 94: ['a large mug', '1 tablespoon', 'softened butter', 'the microwave'],\n",
      " 95: ['Sprinkle 1/4 teaspoon cinnamon', 'the egg'],\n",
      " 96: ['the contents', 'plate'],\n",
      " 97: [\"the mug's contents\", 'a plate'],\n",
      " 98: ['the butter', 'the mug'],\n",
      " 99: ['1 slices', 'bread', 'bite-size pieces'],\n",
      " 100: ['1/4 teaspoon vanilla extract', 'the mug'],\n",
      " 101: ['the mug', 'one egg', 'a fork'],\n",
      " 102: ['floss', '1 more pinwheel'],\n",
      " 103: ['Discard', 'the tortilla'],\n",
      " 104: ['the knife', 'a paper towel'],\n",
      " 105: [\"the floss's two ends\", \"the tortilla roll's top\"],\n",
      " 106: ['Slide floss', 'the tortilla', 'the length', 'the roll'],\n",
      " 107: ['the nut butter'],\n",
      " 108: ['the floss', 'opposite directions'],\n",
      " 109: ['the pinwheels', 'a plate'],\n",
      " 110: ['the rolled tortilla', '5 toothpicks'],\n",
      " 111: ['the knife', 'the jar'],\n",
      " 112: ['nut butter', 'the tortilla', '1/2-inch', 'the edges'],\n",
      " 113: ['a butter knife', 'nut butter', 'the jar'],\n",
      " 114: ['the ends',\n",
      "       'the tortilla roll',\n",
      "       'the butter knife',\n",
      "       '1/2 inch margin',\n",
      "       'the last toothpick',\n",
      "       'the end',\n",
      "       'the roll'],\n",
      " 115: ['Place 8-inch flour tortilla', 'board'],\n",
      " 116: ['the tortilla', 'one end', 'a log shape', 'gaps', 'the filling leaks'],\n",
      " 117: ['the floss', 'toothpicks'],\n",
      " 118: ['the knife', 'a paper towel'],\n",
      " 119: ['Slice', 'one tomato', 'about 1/2 inch thick slices'],\n",
      " 120: ['the thick slices', 'tomatoes', 'a platter', 'they', 'a single layer'],\n",
      " 121: ['a drizzle', 'extra-virgin olive oil', 'the entire platter'],\n",
      " 122: ['a paper/tea towel'],\n",
      " 123: ['Season', 'the tomato slices', 'salt'],\n",
      " 124: ['mozzarella cheese', 'top', 'the tomato', 'the platter'],\n",
      " 125: [],\n",
      " 126: ['Season platter', '1/4 teaspoon black pepper'],\n",
      " 127: ['Garnish platter', 'italian seasoning'],\n",
      " 128: ['lime juice', 'the bowl'],\n",
      " 129: ['Measure', '2 cups', 'frozen corn'],\n",
      " 130: ['1 teaspoon', 'pepper powder', 'the bowl'],\n",
      " 131: ['Extract lime juice', '1/3 lime'],\n",
      " 132: ['the corn', 'a microwave-safe bowl'],\n",
      " 133: ['the corn', '2 minutes'],\n",
      " 134: ['the corn', '3 more minutes'],\n",
      " 135: ['the bowl'],\n",
      " 136: ['1 teaspoon salt', 'the bowl'],\n",
      " 137: ['Thaw the frozen corn', 'a sieve', 'cold water'],\n",
      " 138: ['1 teaspoon', 'softened butter'],\n",
      " 139: ['1/4 tsp mustard', 'the pan'],\n",
      " 140: ['the garlic'],\n",
      " 141: ['1/2 tsp cumin', 'the pan'],\n",
      " 142: ['tomato puree', 'the pan'],\n",
      " 143: ['the pan', 'the heat'],\n",
      " 144: ['contents', 'the pan'],\n",
      " 145: ['Peel', '4 large garlic cloves'],\n",
      " 146: ['1/2 tsp salt', 'the pan'],\n",
      " 147: ['2 tbsp red chili powder', 'the pan'],\n",
      " 148: ['the garlic', '2-3 minutes'],\n",
      " 149: [],\n",
      " 150: ['puree tomatoes', 'any water', 'a blender/mixer'],\n",
      " 151: ['the heat'],\n",
      " 152: ['mustard', 'cumin seeds', 'minced garlic'],\n",
      " 153: ['the mixture', 'low heat', '5 minutes', 'the mixture'],\n",
      " 154: ['Heat', '3 tbsp oil', 'a pan', 'medium heat'],\n",
      " 155: ['Chop tomato', 'anysize chunks'],\n",
      " 156: ['a serving bowl'],\n",
      " 157: ['well contents', 'the pan'],\n",
      " 158: ['Chop 1 tsp cilantro'],\n",
      " 159: ['the egg mixture', 'the bowl'],\n",
      " 160: ['garlic', 'the pan'],\n",
      " 161: ['Chop', '1 green chilli'],\n",
      " 162: ['chilli', 'the pan'],\n",
      " 163: ['Chop 1/4 medium onion'],\n",
      " 164: ['1/3 tsp salt', 'the bowl'],\n",
      " 165: ['1 minute', 'everything'],\n",
      " 166: ['the onions', 'medium heat', 'they'],\n",
      " 167: ['one egg', 'the bowl'],\n",
      " 168: ['1/8 tsp', 'turmeric', 'the pan'],\n",
      " 169: ['Chop', '1/4 tomato'],\n",
      " 170: ['Cook', '1 minute', 'the tomatoes'],\n",
      " 171: ['a spatula', '3 minutes', 'the eggs'],\n",
      " 172: ['the whisked eggs', 'the pan'],\n",
      " 173: ['Heat', '2 tbsp oil', 'a heavy-bottomed or nonstick pan', 'medium heat'],\n",
      " 174: ['1 tbsp', 'cilantro'],\n",
      " 175: ['tomatoes', 'the pan'],\n",
      " 176: ['Peel 2 garlic cloves'],\n",
      " 177: ['1 tbsp milk', 'the bowl'],\n",
      " 178: ['1/3 tsp salt', 'the pan'],\n",
      " 179: ['chopped onions', 'the pan'],\n",
      " 180: ['Mince peeled garlic cloves'],\n",
      " 181: ['1/4 teaspoon', 'red chilli powder', 'the bowl'],\n",
      " 182: ['the cucumber'],\n",
      " 183: ['a mixing bowl',\n",
      "       '1 cup',\n",
      "       'chilled curd',\n",
      "       'fresh homemade or packaged curd'],\n",
      " 184: ['1/4 teaspoon salt', 'the bowl'],\n",
      " 185: ['chop', 'the cucumber'],\n",
      " 186: ['all the ingredients', 'the bowl'],\n",
      " 187: ['1 tablespoon', 'chopped cilantro leaves', 'the bowl'],\n",
      " 188: ['1 teaspoon', 'cumin powder', 'the bowl'],\n",
      " 189: ['Rinse 1 medium sized cucumber'],\n",
      " 190: ['the chopped or grated cucumber', 'the whisked curd'],\n",
      " 191: ['1/2 teaspoon', 'chaat masala powder', 'the bowl'],\n",
      " 192: ['2 minutes', 'the zoodles'],\n",
      " 193: ['1/6 cup', 'parmesan cheese'],\n",
      " 194: ['pepper'],\n",
      " 195: ['more parmesan'],\n",
      " 196: ['a large pan', 'medium heat'],\n",
      " 197: ['heat'],\n",
      " 198: ['season', 'salt'],\n",
      " 199: ['1 large minced garlic cloves', 'the pan'],\n",
      " 200: ['Peel 1 garlic cloves'],\n",
      " 201: ['the zucchini noodles'],\n",
      " 202: ['Cook garlic', 'about 1 minutes'],\n",
      " 203: ['Spiralize', '1 medium zucchini', 'thin noodles', 'a spiralizer'],\n",
      " 204: ['1 tablespoons', 'softened butter'],\n",
      " 205: ['pat rinsed mushrooms', 'a paper towel'],\n",
      " 206: ['Rinse', '3 mushrooms', 'cold water'],\n",
      " 207: ['the pan', '1 minute'],\n",
      " 208: ['the pan', 'the mushrooms'],\n",
      " 209: ['shallot', 'the pan'],\n",
      " 210: ['the mushrooms'],\n",
      " 211: ['mince garlic cloves'],\n",
      " 212: ['Chop', '1 shallot'],\n",
      " 213: ['3-5 minutes', 'mushrooms'],\n",
      " 214: ['mushroom'],\n",
      " 215: ['Heat 1 tbsp olive oil', 'a large skillet', 'medium-high heat'],\n",
      " 216: ['the contents', 'the pan', 'a serving dish'],\n",
      " 217: ['1/4 tbsp balsamic vinegar', 'the pan'],\n",
      " 218: ['2 cloves', 'minced garlic', 'the pan'],\n",
      " 219: ['pepper', 'pan'],\n",
      " 220: ['Season pan', 'salt'],\n",
      " 221: ['1/2 tsp', 'powder', 'a blender'],\n",
      " 222: ['the pancakes', 'chopped strawberries'],\n",
      " 223: ['a small knob', 'butter', 'a non-stick frying pan', 'low-medium heat'],\n",
      " 224: ['maple syrup', 'plate'],\n",
      " 225: ['1 banana', 'a blender'],\n",
      " 226: ['1 min', 'the tops', 'bubble'],\n",
      " 227: ['blitz', 'the blender', '20 seconds'],\n",
      " 228: ['the pancakes', 'a fork', 'a fish slice spatula'],\n",
      " 229: ['1 egg', 'a blender'],\n",
      " 230: [],\n",
      " 231: ['three little puddles', 'the blender', 'the frying pan'],\n",
      " 232: ['1 heaped tbsp flour', 'a blender'],\n",
      " 233: ['Chop'],\n",
      " 234: ['a plate'],\n",
      " 235: ['Heat', '1 tbsp oil', 'a non-stick frying pan'],\n",
      " 236: ['tomatoes', 'a serving plate'],\n",
      " 237: ['Chop 2 tbsp cilantro'],\n",
      " 238: ['a wooden spoon',\n",
      "       'the base',\n",
      "       'the pan moves',\n",
      "       'the uncooked egg',\n",
      "       'the space'],\n",
      " 239: ['one egg', 'a bowl'],\n",
      " 240: ['the tomatoes cut-side', 'they'],\n",
      " 241: ['the egg mixture', 'the pan'],\n",
      " 242: ['the chopped cilantro', 'the bowl'],\n",
      " 243: ['Transfer', 'omelette', 'the plate', 'the tomatoes'],\n",
      " 244: ['the tomatoes', 'the pan'],\n",
      " 245: ['an omelette'],\n",
      " 246: ['tomato', 'two pieces'],\n",
      " 247: ['a tomato'],\n",
      " 248: ['the contents', 'the bowl'],\n",
      " 249: ['1/2 tsp ground black pepper', 'the bowl'],\n",
      " 250: ['1/8 cup soy sauce', 'the bowl'],\n",
      " 251: ['the sauce mixture'],\n",
      " 252: ['1 tablespoon honey', 'the bowl'],\n",
      " 253: ['cook', '4 minutes', 'the pan', 'the heat'],\n",
      " 254: ['1 teaspoon cornstarch', 'the bowl'],\n",
      " 255: ['2 cloves', 'minced garlic', 'the bowl'],\n",
      " 256: ['the sauce', 'the skillet'],\n",
      " 257: ['Peel', '2 cloves', 'garlic'],\n",
      " 258: ['sliced mushrooms', 'the skillet'],\n",
      " 259: ['slice mushrooms'],\n",
      " 260: ['the contents', 'bowl'],\n",
      " 261: ['bell pepper', 'the skillet'],\n",
      " 262: ['mince garlic'],\n",
      " 263: ['slice', 'the bell pepper'],\n",
      " 264: ['cook', '1 minute', 'the sauce'],\n",
      " 265: ['broccoli', 'the skillet'],\n",
      " 266: ['Heat', '2 tablespoons olive oil', 'a skillet', 'medium-high heat'],\n",
      " 267: ['1/2 tablespoon minced ginger', 'the bowl'],\n",
      " 268: ['1/8 teaspoon black pepper', 'the bowl'],\n",
      " 269: ['1/6 cup water', 'the bowl'],\n",
      " 270: ['2 cremini mushrooms'],\n",
      " 271: ['1 bell pepper'],\n",
      " 272: ['the sauce', 'the ingredients'],\n",
      " 273: ['number broccoli', 'florets'],\n",
      " 274: ['2-3 minutes', 'vegetables'],\n",
      " 275: ['1/4 block', '3 ounces', 'fresh tofu', 'large cubes'],\n",
      " 276: ['the heat'],\n",
      " 277: ['1 tablespoon soy sauce', 'the pan'],\n",
      " 278: ['the 1 tablespoons', 'oil', 'the pan'],\n",
      " 279: ['the tofu cubes', 'the pan'],\n",
      " 280: ['the pan', 'the heat'],\n",
      " 281: ['flip tofu', 'the pan'],\n",
      " 282: ['the heat'],\n",
      " 283: ['a serving dish'],\n",
      " 284: ['low heat'],\n",
      " 285: ['the tofu', 'tongs'],\n",
      " 286: ['1/4 tsp salt', 'the pan'],\n",
      " 287: ['the heat'],\n",
      " 288: ['pan', '2 minutes', 'the colour'],\n",
      " 289: ['pan', '2 minutes'],\n",
      " 290: ['tofu'],\n",
      " 291: ['1 tablespoon', 'olive oil', 'a non-stick pan'],\n",
      " 292: ['Cook', '5 to 6 minutes', 'tofu cubes', 'the bottom'],\n",
      " 293: ['pat tofu', 'a towel'],\n",
      " 294: ['Whisk batter', 'no lumps'],\n",
      " 295: ['the paper liner'],\n",
      " 296: ['2 tbsp water', 'the bowl'],\n",
      " 297: ['1.5 tbsp sugar', 'the mixing bowl'],\n",
      " 298: ['the cake',\n",
      "       'the frosting',\n",
      "       'Scoop 4 spoonfuls',\n",
      "       'chocolate',\n",
      "       'a zip-top bag'],\n",
      " 299: ['Measure', '2 tbsp flour', 'the mixing bowl'],\n",
      " 300: ['Measure', '2 tsp vegetable oil', 'the bowl'],\n",
      " 301: ['the lined mug'],\n",
      " 302: ['the frosting',\n",
      "       'the opening',\n",
      "       'small dollops',\n",
      "       'the plate',\n",
      "       'a circle',\n",
      "       'the base',\n",
      "       'the cake'],\n",
      " 303: ['the paper cupcake liner', 'the mug'],\n",
      " 304: ['1/4 tsp', 'powder', 'the bowl'],\n",
      " 305: ['the touch'],\n",
      " 306: ['scissors',\n",
      "       'one corner',\n",
      "       'the bag',\n",
      "       'a small opening 1/4 inch',\n",
      "       'diameter'],\n",
      " 307: ['batter', 'prepared mug'],\n",
      " 308: ['mixture', 'flour, sugar and baking powder', 'the bowl'],\n",
      " 309: ['Invert', 'the mug', 'the cake', 'a plate'],\n",
      " 310: ['a pinch', 'salt', 'the mixing bowl'],\n",
      " 311: ['zip top bag', 'as much air'],\n",
      " 312: ['the mug',\n",
      "       'high power',\n",
      "       '60 seconds',\n",
      "       'the cake',\n",
      "       'inserting',\n",
      "       'the center',\n",
      "       'the cake',\n",
      "       'batter clings',\n",
      "       'the toothpick, microwave',\n",
      "       'an additional 5 seconds',\n",
      "       'the toothpick'],\n",
      " 313: ['1/4 tsp vanilla', 'the bowl'],\n",
      " 314: ['1/2 tbsp', 'butter', 'the bowl'],\n",
      " 315: ['1/4 teaspoon salt', 'the bowl'],\n",
      " 316: ['1/3 cup cheddar cheese', 'a microwave-safe cup'],\n",
      " 317: ['the cheese', 'red bell pepper', 'the bowl'],\n",
      " 318: ['the bowl', '2 minutes'],\n",
      " 319: ['1/4 teaspoon pepper', 'the bowl'],\n",
      " 320: ['1 tablespoons', 'water', 'the bowl'],\n",
      " 321: ['Chop 1/4 red bell pepper', 'tiny bits'],\n",
      " 322: ['the chopped pepper', 'the microwave-safe bowl'],\n",
      " 323: ['the cheese', 'microwaving cup', '30 sec', '30 seconds'],\n",
      " 324: ['all the ingredients', 'the bowl'],\n",
      " 325: ['place', 'slices', 'each leaf'],\n",
      " 326: ['season 1/4 tsp pepper', 'the bowl'],\n",
      " 327: ['1/4 cup mayonnaise', 'the bowl'],\n",
      " 328: ['excess water'],\n",
      " 329: ['2 large lettuce leaves'],\n",
      " 330: ['the lettuce wraps'],\n",
      " 331: ['the contents', 'the bowl'],\n",
      " 332: ['top lettuce', 'the tuna mixture'],\n",
      " 333: ['chopped scallion', 'the bowl'],\n",
      " 334: ['tuna', 'the bowl'],\n",
      " 335: ['1 ripe avocado'],\n",
      " 336: ['a can', 'tuna'],\n",
      " 337: ['the wrap'],\n",
      " 338: ['Season bowl', '1/4 tsp salt'],\n",
      " 339: ['Sriracha', 'the bowl'],\n",
      " 340: ['Chop', 'scallion'],\n",
      " 341: ['avocado', 'thin slices'],\n",
      " 342: ['1/8 cup', 'mozzarella', 'a bowl'],\n",
      " 343: ['1/4 tsp salt', 'a bowl'],\n",
      " 344: ['Slice', 'two 1/2 inch thick rounds', 'a baguette', 'slice slanted'],\n",
      " 345: ['the mixture', 'the bowl', 'the bread'],\n",
      " 346: ['1/4 tsp pepper', 'a bowl'],\n",
      " 347: ['1/16 cup basil', 'a bowl'],\n",
      " 348: ['the contents', 'the bowl'],\n",
      " 349: ['Brush', '2 slices', 'baguette', 'olive oil', 'both sides'],\n",
      " 350: ['Cut 1/4 cup', 'cherry tomatoes', 'halves'],\n",
      " 351: ['a bowl', 'the cut cherry tomatoes'],\n",
      " 352: ['both sides',\n",
      "       'the slices',\n",
      "       'the pan',\n",
      "       '2 to 3 minutes',\n",
      "       'the slices',\n",
      "       'a plate']}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from pprint import pprint\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "RECIPE_STEP_OBJECTS = {}\n",
    "for step_id, step in RECIPE_STEPS.items():\n",
    "    # Process the sentence\n",
    "    doc = nlp(step)\n",
    "\n",
    "    # Extract noun phrases\n",
    "    noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    noun_phrases = [np for np in noun_phrases if np.lower() not in [\"you\", \"this step\", \"it\", \"about 30 seconds\", \"that\"]]\n",
    "    \n",
    "    # TODO: This could be improved further, e.g., using an LM - a lot of noise in this\n",
    "    \n",
    "    RECIPE_STEP_OBJECTS[step_id] = noun_phrases\n",
    "    \n",
    "pprint(RECIPE_STEP_OBJECTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06d0f5-7849-4664-b0e2-691de792ab6d",
   "metadata": {},
   "source": [
    "Generate success verification questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8678903-3bdf-47fe-845e-fad45fa8b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Coat a 6-oz. ramekin cup with cooking spray\n",
      "[('1. Is the ramekin cup coated with cooking spray?', 'Yes'),\n",
      " ('2. Is the ramekin cup 6 ounces?', 'Yes')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/350 [01:14<7:12:55, 74.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Coat a 6-oz. ramekin cup with cooking spray\n",
      "[('1. Is the ramekin cup coated with cooking spray?', 'Yes'),\n",
      " ('2. Is the ramekin cup coated with cooking spray?', 'Yes')]\n",
      "===========================================================================\n",
      "Pour 1 egg into the ramekin cup\n",
      "[('1. Is there an egg in the ramekin cup?', 'Yes'),\n",
      " ('2. Is the egg whole?', 'Yes')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sstorks/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "  0%|          | 1/350 [02:12<12:53:31, 132.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe recipe step is \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. To visually verify that this step is complete, what are some questions we could ask about an image of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoun_phrase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and their expected answers?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([example1, example2, example3, test])\n\u001b[0;32m---> 25\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     28\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(example1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(example2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(example3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     29\u001b[0m questions_answers \u001b[38;5;241m=\u001b[39m [(q_a\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m, q_a\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m q_a \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]] \u001b[38;5;66;03m# NOTE: only extract k=2 questions and answers; can adjust this as needed later\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:219\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1162\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1155\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1156\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m     )\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1169\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1168\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1169\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/pipelines/base.py:1068\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1067\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1068\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:295\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/generation/utils.py:1479\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1463\u001b[0m         input_ids,\n\u001b[1;32m   1464\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1476\u001b[0m     )\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/generation/utils.py:2340\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2337\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2340\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2341\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2348\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1183\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1180\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1183\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1070\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1061\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1062\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         use_cache,\n\u001b[1;32m   1068\u001b[0m     )\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1070\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:812\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    811\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 812\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    815\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:268\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:450\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 450\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCxB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;66;03m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;66;03m# we no longer need the row-major weight\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:562\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    561\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:404\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    401\u001b[0m out32, Sout32 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39migemmlt(C32A, state\u001b[38;5;241m.\u001b[39mCxB, SA, state\u001b[38;5;241m.\u001b[39mSB)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# we apply the fused bias here\u001b[39;00m\n\u001b[0;32m--> 404\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm_dequant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSout32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSCB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto(A\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# apply bias separately\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/bitsandbytes/functional.py:1961\u001b[0m, in \u001b[0;36mmm_dequant\u001b[0;34m(A, quant_state, row_stats, col_stats, out, new_row_stats, new_col_stats, bias)\u001b[0m\n\u001b[1;32m   1959\u001b[0m is_on_gpu([A, row_stats, col_stats, out, new_row_stats, new_col_stats, bias])\n\u001b[1;32m   1960\u001b[0m lib\u001b[38;5;241m.\u001b[39mcdequant_mm_int32_fp16(ptrA, ptrRowStats, ptrColStats, ptrOut, ptrNewRowStats, ptrNewColStats, ptrBias, numRows, numCols)\n\u001b[0;32m-> 1961\u001b[0m \u001b[43mpost_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/bitsandbytes/functional.py:422\u001b[0m, in \u001b[0;36mpost_call\u001b[0;34m(prev_device)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_call\u001b[39m(prev_device):\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/cuda/__init__.py:324\u001b[0m, in \u001b[0;36mset_device\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_device\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the current device.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    Usage of this function is discouraged in favor of :any:`device`. In most\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m            if this argument is negative.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_get_device_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    326\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_setDevice(device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/travel-nQET-zRt-py3.10/lib/python3.10/site-packages/torch/cuda/_utils.py:32\u001b[0m, in \u001b[0;36m_get_device_index\u001b[0;34m(device, optional, allow_cpu)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected a cuda device, but got: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m device\u001b[38;5;241m.\u001b[39midx\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _torch_get_device_index(device, optional, allow_cpu)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "example1 = 'The recipe step is \"Spoon the mixture from the bowl onto the bread\". To visually verify that this step is complete, what are some questions we could ask about an image of the bread and their expected answers?\\n' \\\n",
    "           '1. Is there mixture on the bread? Yes\\n' \\\n",
    "           '2. Is there any bread without any mixture on top of it? No' \\\n",
    "\n",
    "example2 = 'The recipe step is \"Roll the tortilla into a thin, log shape about 1 inch thick. Make sure no filling leaks out.\". To visually verify that this step is complete, what are some questions we could ask about an image of the tortilla and their expected answers?\\n' \\\n",
    "           '1. Is the tortilla in a thin log shape? Yes\\n' \\\n",
    "           '2. Is there any filling leaking out of the tortilla? No'\n",
    "\n",
    "example3 = 'The recipe step is \"Fold the coffee filter into quarters\". To visually verify that this step is complete, what are some questions we could ask about an image of the coffee filter and their expected answers?\\n' \\\n",
    "           '1. Is the coffee filter in a quarter circle? Yes\\n' \\\n",
    "           '2. Is the coffee filter folded? Yes' \\\n",
    "\n",
    "vqg_outputs = {}\n",
    "with torch.no_grad():\n",
    "    # TODO: make this more efficient later\n",
    "    for step_id, step in tqdm(RECIPE_STEPS.items()):\n",
    "        vqg_outputs[step_id] = {}\n",
    "        for noun_phrase in RECIPE_STEP_OBJECTS[step_id]:\n",
    "        \n",
    "            test = f'The recipe step is \"{step}\". To visually verify that this step is complete, what are some questions we could ask about an image of {noun_phrase} and their expected answers?\\n'\n",
    "\n",
    "            prompt = \"\\n\\n\".join([example1, example2, example3, test])\n",
    "\n",
    "            text = model(prompt, \n",
    "                         max_new_tokens=256, \n",
    "                         do_sample=False)[0]['generated_text']\n",
    "            text = text.replace(example1, \"\").replace(example2, \"\").replace(example3, \"\").strip()\n",
    "            questions_answers = [(q_a.split(\"?\")[0].strip() + \"?\", q_a.split(\"?\")[1].strip()) for q_a in text.split(\"\\n\")[1:3]] # NOTE: only extract k=2 questions and answers; can adjust this as needed later\n",
    "\n",
    "            print(\"===========================================================================\")\n",
    "            print(step)\n",
    "            pprint(questions_answers)\n",
    "\n",
    "            vqg_outputs[step_id][noun_phrase] = questions_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcb8ec-1556-47f3-826c-919bd71c40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(vqg_outputs, open(\"cache_dir/vqg_outputs.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a975ce-5389-48c1-8d78-6a4847c99145",
   "metadata": {},
   "source": [
    "## Step 2: VQA with LLaVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51a976-d86c-442a-b600-b99e26504098",
   "metadata": {},
   "source": [
    "Load model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f55dbf-5abc-4763-8c61-e51c28a7e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code grabbed from docs: https://huggingface.co/docs/transformers/model_doc/llava#transformers.LlavaForConditionalGeneration\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "\n",
    "MODEL_NAME = \"llava-hf/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR, load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d2305-c055-4946-b72a-71e9b9cb7b33",
   "metadata": {},
   "source": [
    "Ask success verification questions per frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6b7b5-e552-4da4-85a2-a23350f2476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "examples = success_examples[:20] + error_examples[:20]\n",
    "examples = examples[:1] # Just for debug purposes\n",
    "\n",
    "prompt_template = \"USER: <image>\\n{question} (yes/no) ASSISTANT: \"\n",
    "\n",
    "vqa_outputs = []\n",
    "with torch.no_grad():\n",
    "    for example in examples:\n",
    "        this_vqa_outputs = []\n",
    "        \n",
    "        questions_answers = [QA for noun_phrase in vqg_outputs[step_idx] for QA in vqg_outputs[step_idx][noun_phrase]]\n",
    "        prompts = [prompt_template.format(question=question) for question, _ in questions_answers]\n",
    "        expected_answers = [answer for _, answer in questions_answers]\n",
    "                           \n",
    "        # TODO: make more efficient for full evaluation; will need to mess around with padding, ensure padding token is on correct side\n",
    "        for frame in example.frames:\n",
    "            for prompt, expected_answer in zip(prompts, expected_answers):\n",
    "                inputs = processor(text=prompt, images=frame, return_tensors=\"pt\").to(device)\n",
    "\n",
    "                # Generate\n",
    "                logits = model(**inputs).logits[0] # (seq length, vocab size)\n",
    "                no_logit = logits[-1, NO_ID]\n",
    "                yes_logit = logits[-1, YES_ID]\n",
    "                probs = torch.softmax(torch.stack((no_logit, yes_logit), dim=0), dim=0).detach().cpu()\n",
    "                \n",
    "                if probs[0] <= 0.5:\n",
    "                    pred = \"No\"\n",
    "                else:\n",
    "                    pred = \"Yes\"                \n",
    "                \n",
    "                this_vqa_outputs.append((frame, prompt, probs, pred, expected_answer))\n",
    "                \n",
    "        vqa_outputs.append(this_vqa_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bdde0-974c-403e-b448-9d1342841de4",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate VQA Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910966f-cc39-4c12-9d8c-a2c3595a73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example, outputs in zip(examples, vqa_outputs):\n",
    "    mistake_predictions = []\n",
    "    for frame, prompt, probs, pred, expected_answer in outputs:\n",
    "        if pred != expected_answer:\n",
    "            predicted_mistake = True\n",
    "        else:\n",
    "            predicted_mistake = False\n",
    "        mistake_predictions.append(predicted_mistake)\n",
    "                \n",
    "    pprint(mistake_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel",
   "language": "python",
   "name": "travel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
